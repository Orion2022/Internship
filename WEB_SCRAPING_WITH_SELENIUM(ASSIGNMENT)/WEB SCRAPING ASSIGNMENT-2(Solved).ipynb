{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Importing selenium webdriver \n",
    "from selenium import webdriver\n",
    "\n",
    "# Importing required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "#Importing requests\n",
    "import requests\n",
    "\n",
    "import undetected_chromedriver as uc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path for chromedriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"start-maximized\")\n",
    "driver = uc.Chrome(executable_path='chromedriver.exe', options=options)\n",
    "keyword = \"https://www.naukri.com/\"\n",
    "driver.get(keyword)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing “Data Analyst” in “Skill,Designations,Companies” field.\n",
    "search_job=driver.find_element_by_xpath(\"//input[@class='sugInp']\") #job search bar\n",
    "search_job.send_keys(\"Data Analyst\")\n",
    "\n",
    "# Writing “Bangalore” in “enter the location” field.\n",
    "search_location=driver.find_element_by_id('qsb-location-sugg') #location search bar\n",
    "search_location.send_keys(\"Bangalore\")\n",
    "\n",
    "# clicking the search button\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:502: UserWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  warnings.warn(\"find_elements_by_* commands are deprecated. Please use find_elements() instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Gaussian Networks Private Limited</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tcs Hiring For Senior Data Analyst (bfsi domain)</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Trigent Software</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Trigent Software</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business Data Analyst - Google Data Studio &amp; SQL</td>\n",
       "      <td>AVE-Promagne</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Virtusa Consulting Services Pvt Ltd</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram...</td>\n",
       "      <td>8-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tcs Hiring For MDM (master data management) Da...</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Analyst IDAM Services</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst/Sr.Data Engineer</td>\n",
       "      <td>SYREN TECHNOLOGIES PRIVATE LIMITED</td>\n",
       "      <td>Hyderabad/Secunderabad, Chennai, Bangalore/Ben...</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SENIOR DATA ANALYST</td>\n",
       "      <td>McAfee Software (India) Pvt. Ltd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                                Senior Data Analyst   \n",
       "1   Tcs Hiring For Senior Data Analyst (bfsi domain)   \n",
       "2                              Business Data Analyst   \n",
       "3                              Business Data Analyst   \n",
       "4   Business Data Analyst - Google Data Studio & SQL   \n",
       "5                                Senior Data Analyst   \n",
       "6  Tcs Hiring For MDM (master data management) Da...   \n",
       "7                  Senior Data Analyst IDAM Services   \n",
       "8                      Data Analyst/Sr.Data Engineer   \n",
       "9                                SENIOR DATA ANALYST   \n",
       "\n",
       "                              Company Name  \\\n",
       "0        Gaussian Networks Private Limited   \n",
       "1           Tata Consultancy Services Ltd.   \n",
       "2                         Trigent Software   \n",
       "3                         Trigent Software   \n",
       "4                             AVE-Promagne   \n",
       "5      Virtusa Consulting Services Pvt Ltd   \n",
       "6           Tata Consultancy Services Ltd.   \n",
       "7  GlaxoSmithKline Pharmaceuticals Limited   \n",
       "8       SYREN TECHNOLOGIES PRIVATE LIMITED   \n",
       "9         McAfee Software (India) Pvt. Ltd   \n",
       "\n",
       "                                        Job Location Experience Required  \n",
       "0              Gurgaon/Gurugram, Bangalore/Bengaluru             3-5 Yrs  \n",
       "1                       Chennai, Bangalore/Bengaluru            6-11 Yrs  \n",
       "2                                Bangalore/Bengaluru            5-10 Yrs  \n",
       "3                                Bangalore/Bengaluru            5-10 Yrs  \n",
       "4                                Bangalore/Bengaluru             3-8 Yrs  \n",
       "5  Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram...            8-12 Yrs  \n",
       "6                       Chennai, Bangalore/Bengaluru            6-11 Yrs  \n",
       "7                                Bangalore/Bengaluru             4-8 Yrs  \n",
       "8  Hyderabad/Secunderabad, Chennai, Bangalore/Ben...             4-9 Yrs  \n",
       "9                                Bangalore/Bengaluru             6-8 Yrs  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating empty lists for scraping data\n",
    "Job_Title=[]\n",
    "Job_Location=[]\n",
    "Company_Name=[]\n",
    "Experience_Required=[]\n",
    "\n",
    "\n",
    "#scraping the job-titles\n",
    "titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles[:10]:\n",
    "    if i.text is None :\n",
    "        Job_Title.append(\"--\") \n",
    "    else:\n",
    "        Job_Title.append(i.text)\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "#scraping the job-location\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in locations[:10]:\n",
    "    if i.text is None :\n",
    "        Job_Location.append(\"--\") \n",
    "    else:\n",
    "        Job_Location.append(i.text)\n",
    "        \n",
    "time.sleep(3)        \n",
    "#scraping the company_name \n",
    "companies=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in companies[:10]:\n",
    "    if i.text is None :\n",
    "        Company_Name.append(\"--\") \n",
    "    else:\n",
    "        Company_Name.append(i.text)\n",
    "\n",
    "\n",
    "time.sleep(2)\n",
    "#scraping the experience_required \n",
    "experience=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "for i in experience[:10]:\n",
    "    if i.text is None :\n",
    "            Experience_Required.append(\"--\") \n",
    "    else:\n",
    "            Experience_Required.append(i.text)\n",
    "\n",
    "\n",
    "time.sleep(2)\n",
    "# creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df = pd.DataFrame({})\n",
    "df['Job Title']=Job_Title\n",
    "df['Company Name']=Company_Name\n",
    "df['Job Location']=Job_Location\n",
    "df['Experience Required']=Experience_Required\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path for chromedriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"start-maximized\")\n",
    "driver = uc.Chrome(executable_path='chromedriver.exe', options=options)\n",
    "keyword = \"https://www.naukri.com/\"\n",
    "driver.get(keyword)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:443: UserWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  warnings.warn(\"find_element_by_* commands are deprecated. Please use find_element() instead\")\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:483: UserWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  warnings.warn(\"find_element_by_* commands are deprecated. Please use find_element() instead\")\n"
     ]
    }
   ],
   "source": [
    "# entering “Data Scientist” in “Skill,Designations,Companies” field\n",
    "search_job=driver.find_element_by_id(\"qsb-keyword-sugg\")  \n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "# entering “Bangalore” in “enter the location” field.\n",
    "search_location=driver.find_element_by_id('qsb-location-sugg')\n",
    "search_location.send_keys(\"Bangalore\")\n",
    "\n",
    "# clicking the search button\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()\n",
    "\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:502: UserWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  warnings.warn(\"find_elements_by_* commands are deprecated. Please use find_elements() instead\")\n"
     ]
    }
   ],
   "source": [
    "# creating empty lists for scraping data\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "full_job_description=[]\n",
    "\n",
    "\n",
    "#scraping the job-titles\n",
    "titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles[0:10]:\n",
    "    if i.text is None :\n",
    "        job_title.append(\"--\") \n",
    "    else:\n",
    "        job_title.append(i.text)\n",
    "\n",
    "time.sleep(4)\n",
    "#scraping the job-location\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in locations[0:10]:\n",
    "    if i.text is None :\n",
    "        job_location.append(\"--\") \n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "        \n",
    "time.sleep(4)        \n",
    "#scraping the company_name \n",
    "companies=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in companies[0:10]:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Location</th>\n",
       "      <th>Full_Job_Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>Minumum 3 years of experience in Data Science/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lead Data Scientist BFSI</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Use predictive modeling to increase and optimi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Brillio</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>A day in the Life of Data Scientist at Brillio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - I / II</td>\n",
       "      <td>Sharechat</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Responsibilities\\nApply state of the art in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Must Have skill sets:\\n\\nExcellent knowledge o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Walmart Labs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>As a Senior Data Scientist for Walmart, you ll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Airbnb</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Responsibilities include:\\nDefining and evalua...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Job_Title                      Company_Name  \\\n",
       "0           Hiring For Data Scientist    Tata Consultancy Services Ltd.   \n",
       "1            Lead Data Scientist BFSI            IBM India Pvt. Limited   \n",
       "2            Associate Data Scientist             Philips India Limited   \n",
       "3                      Data Scientist                           Brillio   \n",
       "4             Data Scientist - I / II                         Sharechat   \n",
       "5                      Data Scientist  Allegis Services India Pvt. Ltd.   \n",
       "6                      Data Scientist  Allegis Services India Pvt. Ltd.   \n",
       "7  Data Scientist: Advanced Analytics            IBM India Pvt. Limited   \n",
       "8               Senior Data Scientist                      Walmart Labs   \n",
       "9               Senior Data Scientist                            Airbnb   \n",
       "\n",
       "                                       Job_Location  \\\n",
       "0  Chennai, Bangalore/Bengaluru, Mumbai (All Areas)   \n",
       "1                               Bengaluru/Bangalore   \n",
       "2                               Bangalore/Bengaluru   \n",
       "3                               Bangalore/Bengaluru   \n",
       "4                               Bangalore/Bengaluru   \n",
       "5                               Bangalore/Bengaluru   \n",
       "6                               Bangalore/Bengaluru   \n",
       "7                               Bengaluru/Bangalore   \n",
       "8                               Bangalore/Bengaluru   \n",
       "9                               Bangalore/Bengaluru   \n",
       "\n",
       "                                Full_Job_Description  \n",
       "0  Minumum 3 years of experience in Data Science/...  \n",
       "1                                                ---  \n",
       "2  Use predictive modeling to increase and optimi...  \n",
       "3  A day in the Life of Data Scientist at Brillio...  \n",
       "4  Responsibilities\\nApply state of the art in th...  \n",
       "5  Must Have skill sets:\\n\\nExcellent knowledge o...  \n",
       "6                                                ---  \n",
       "7                                                ---  \n",
       "8  As a Senior Data Scientist for Walmart, you ll...  \n",
       "9  Responsibilities include:\\nDefining and evalua...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scraping the full job-description, for scraping full job description we have to go in each of the jobs separately\n",
    "urls=[i.get_attribute(\"href\")for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")]\n",
    "for url in urls[0:10]:\n",
    "    try:\n",
    "        \n",
    "        driver.get(url)\n",
    "        raw_description=driver.find_element_by_xpath(\"//section[@class='job-desc']/div[1]\").text\n",
    "        description=raw_description.replace(\"Contact Person\",\"@@@@@\")\n",
    "        description= description.split(\"@@@@@\")\n",
    "        full_job_description.append(description[0])\n",
    "    except NoSuchElementException :\n",
    "        full_job_description.append(\"---\")\n",
    "\n",
    "# creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df = pd.DataFrame({})\n",
    "df['Job_Title']=job_title\n",
    "df['Company_Name']=company_name\n",
    "df['Job_Location']=job_location\n",
    "df['Full_Job_Description']=full_job_description\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below: You have to use the location and salary filter. You have to scrape data for “Data Scientist” designation for first 10 job results. You have to scrape the job-title, job-location, company_name, experience_required. The location filter to be used is “Delhi/NCR” The salary filter to be used is “3-6” lakhs The task will be done as shown in the below steps:\n",
    "\n",
    "1.first get the webpage https://www.naukri.com/\n",
    "\n",
    "2.Enter “Data Scientist” in “Skill,Designations,Companies” field .\n",
    "\n",
    "3.Then click the search button.\n",
    "\n",
    "4.Then apply the location filter and salary filter by checking the respective boxes\n",
    "\n",
    "5.Then scrape the data for the first 10 jobs results you get.\n",
    "\n",
    "6.Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path for chromedriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"start-maximized\")\n",
    "driver = uc.Chrome(executable_path='chromedriver.exe', options=options)\n",
    "keyword = \"https://www.naukri.com/\"\n",
    "driver.get(keyword)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:483: UserWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  warnings.warn(\"find_element_by_* commands are deprecated. Please use find_element() instead\")\n"
     ]
    }
   ],
   "source": [
    "# entering “Data Scientist” in “Skill,Designations,Companies” field\n",
    "search_job=driver.find_element_by_xpath('//input[@class=\"sugInp\"]')  \n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "\n",
    "# clicking the search button\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()\n",
    "\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(2)\n",
    "\n",
    "# code to click on the location filter for \"Delhi/NCR\"\n",
    "location_filter = driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[3]/label/i')\n",
    "location_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to click on the salary filter for \"3-6 Lakhs\"\n",
    "salary_filter = driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[4]/div[2]/div[2]/label/i')\n",
    "salary_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:502: UserWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  warnings.warn(\"find_elements_by_* commands are deprecated. Please use find_elements() instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Names</th>\n",
       "      <th>Years of experience required</th>\n",
       "      <th>Job Locations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst / Business Analy...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>Ghaziabad, Faridabad, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist/ Machine Learning Engineer</td>\n",
       "      <td>Creative Hands HR Consultancy</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Ahmedabad, Gurga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist / Data Analyst</td>\n",
       "      <td>CARS24</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist / Data Analyst / Business Analy...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>Noida, New Delhi, Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>R Systems International Ltd.</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>PROCESS NINE TECHNOLOGIES PVT.LTD.</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Insurance</td>\n",
       "      <td>Huquo Consulting Pvt. Ltd</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Noida, Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - WFH - MIND Infotech</td>\n",
       "      <td>MOTHERSONSUMI INFOTECH &amp; DESIGNS LIMITED</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Pune, Chennai, Bangalore/Bengaluru, Delhi / NC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Junior Data Scientists &amp; Engineers</td>\n",
       "      <td>PY Consultancy</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>New Delhi, Delhi / NCR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0  Data Scientist / Data Analyst / Business Analy...   \n",
       "1          Data Scientist/ Machine Learning Engineer   \n",
       "2                      Data Scientist / Data Analyst   \n",
       "3  Only Fresher / Data Scientist / Data Analyst /...   \n",
       "4  Data Scientist / Data Analyst / Business Analy...   \n",
       "5                                     Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7                         Data Scientist - Insurance   \n",
       "8               Data Scientist - WFH - MIND Infotech   \n",
       "9                 Junior Data Scientists & Engineers   \n",
       "\n",
       "                              Company Names Years of experience required  \\\n",
       "0                 GABA Consultancy services                      0-0 Yrs   \n",
       "1             Creative Hands HR Consultancy                      0-0 Yrs   \n",
       "2                                    CARS24                      1-5 Yrs   \n",
       "3                 GABA Consultancy services                      0-0 Yrs   \n",
       "4                 GABA Consultancy services                      0-0 Yrs   \n",
       "5              R Systems International Ltd.                      3-6 Yrs   \n",
       "6        PROCESS NINE TECHNOLOGIES PVT.LTD.                      1-3 Yrs   \n",
       "7                 Huquo Consulting Pvt. Ltd                      2-7 Yrs   \n",
       "8  MOTHERSONSUMI INFOTECH & DESIGNS LIMITED                      3-7 Yrs   \n",
       "9                            PY Consultancy                      0-3 Yrs   \n",
       "\n",
       "                                       Job Locations  \n",
       "0                  Ghaziabad, Faridabad, Delhi / NCR  \n",
       "1  Hyderabad/Secunderabad, Pune, Ahmedabad, Gurga...  \n",
       "2                                   Gurgaon/Gurugram  \n",
       "3               Noida, Gurgaon/Gurugram, Delhi / NCR  \n",
       "4                 Noida, New Delhi, Gurgaon/Gurugram  \n",
       "5                                              Noida  \n",
       "6                                   Gurgaon/Gurugram  \n",
       "7                            Noida, Gurgaon/Gurugram  \n",
       "8  Pune, Chennai, Bangalore/Bengaluru, Delhi / NC...  \n",
       "9                             New Delhi, Delhi / NCR  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating empty lists for scraping data\n",
    "Job_Title=[]\n",
    "Job_Location=[]\n",
    "Company_Name=[]\n",
    "Experience_Required=[]\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "# scraping all the job titles\n",
    "j_title = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in j_title[:10]:\n",
    "    if i.text is None :\n",
    "        Job_Title.append(\"--\")\n",
    "    else:\n",
    "        Job_Title.append(i.text)\n",
    "\n",
    "# scraping all the company names\n",
    "j_company = driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in j_company[:10]:\n",
    "    if i.text is None :\n",
    "        Company_Name.append(\"--\")\n",
    "    else:\n",
    "        Company_Name.append(i.text)\n",
    "    \n",
    "    \n",
    "# scraping the years of experience needed\n",
    "j_exp = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in j_exp[:10]:\n",
    "    if i.text is None :\n",
    "        Experience_Required.append(\"--\")\n",
    "    else:\n",
    "        Experience_Required.append(i.text)\n",
    "\n",
    "# scraping all the job locations including Bangalore and the others with it\n",
    "j_location = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]/span[1]')\n",
    "for i in j_location[:10]:\n",
    "    if i.text is None :\n",
    "        Job_Location.append(\"--\")\n",
    "    else:\n",
    "        Job_Location.append(i.text)\n",
    "\n",
    "\n",
    "# creating the data frame now\n",
    "df = pd.DataFrame({})\n",
    "df['Job Title']=Job_Title\n",
    "df['Company Names']=Company_Name\n",
    "df['Years of experience required']=Experience_Required\n",
    "df['Job Locations']=Job_Location\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida” in “location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get in the above shown page.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the web driver\n",
    "driver= webdriver.Chrome(executable_path='chromedriver.exe') \n",
    "time.sleep(2)\n",
    "\n",
    "# getting the glassdoor job search portal url on the web driver\n",
    "url = \"https://www.glassdoor.co.in/index.htm\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to write Data Scientist on skills search box\n",
    "search_job = driver.find_element_by_xpath('//input[@id=\"sc.keyword\"]')\n",
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to write Noida in location box\n",
    "search_loc = driver.find_element_by_xpath('//input[@id=\"sc.location\"]')\n",
    "search_loc.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to click on the search button\n",
    "search_btn = driver.find_element_by_xpath('//button[@class=\"gd-ui-button ml-std col-auto search__SearchStyles__newSearchButton css-1dqvyh7\"]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Job posted duration</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AlgoScale Technologies Private Limited</td>\n",
       "      <td>19d</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Liberin Technologies Private Limited</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Noisy Lion</td>\n",
       "      <td>4d</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenskart</td>\n",
       "      <td>7d</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Grail Insights</td>\n",
       "      <td>5d</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Techlive</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Genpact</td>\n",
       "      <td>7d</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Grail Insights</td>\n",
       "      <td>5d</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Newgen Software</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Company Name Job posted duration Rating\n",
       "0  AlgoScale Technologies Private Limited                 19d    3.9\n",
       "1    Liberin Technologies Private Limited                30d+    3.9\n",
       "2                              Noisy Lion                  4d    3.6\n",
       "3            Salasar New Age Technologies                30d+    3.5\n",
       "4                                Lenskart                  7d    3.8\n",
       "5                          Grail Insights                  5d    3.5\n",
       "6                                Techlive                30d+    3.3\n",
       "7                                 Genpact                  7d    4.1\n",
       "8                          Grail Insights                  5d    4.2\n",
       "9                         Newgen Software                30d+    3.8"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating empty lists for scraping data\n",
    "name=[]\n",
    "days_ago=[]\n",
    "rating=[]\n",
    "\n",
    "# scraping all the company names\n",
    "job_names = driver.find_elements_by_xpath('//a[@class=\" job-search-key-l2wjgv e1n63ojh0 jobLink\"]//span')\n",
    "for i in job_names[:10]:\n",
    "    name.append(i.text)\n",
    "\n",
    "# list the number of days ago the job was posted\n",
    "job_age = driver.find_elements_by_xpath('//div[@data-test=\"job-age\"]')\n",
    "for i in job_age[:10]:\n",
    "    days_ago.append(i.text)\n",
    "\n",
    "# scraping the rating of the companies\n",
    "job_rating = driver.find_elements_by_xpath('//span[@class=\" job-search-key-srfzj0 e1cjmv6j0\"]')\n",
    "for i in job_rating[:10]:\n",
    "    rating.append(i.text)\n",
    "\n",
    "\n",
    "# creating the data frame now\n",
    "df = pd.DataFrame({})\n",
    "df['Company Name']=name\n",
    "df['Job posted duration']=days_ago\n",
    "df['Rating']=rating\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "3. Click the search button.\n",
    "4. After that you will land on the below page. You have to scrape whole data from this webpage\n",
    "5. Scrape data for first 10 companies. Scrape the min salary, max salary, company name, Average salary and rating of the company.\n",
    "6.Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the web driver\n",
    "driver= webdriver.Chrome(executable_path='chromedriver.exe') \n",
    "time.sleep(2)\n",
    "\n",
    "# getting the glassdoor job search portal url on the web driver\n",
    "url = \"https://www.glassdoor.co.in/Salaries/index.htm\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to write Data Scientist on skills search box\n",
    "search_job = driver.find_element_by_xpath('//input[@id=\"KeywordSearch\"]')\n",
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to write Noida in location box\n",
    "search_loc = driver.find_element_by_xpath('//input[@id=\"LocationSearch\"]')\n",
    "search_loc.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to click on the search button\n",
    "search_btn = driver.find_element_by_xpath('//button[@id=\"HeroSearchButton\"]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Company Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>₹4L</td>\n",
       "      <td>₹13L</td>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹6,28,021</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>₹1L</td>\n",
       "      <td>₹28L</td>\n",
       "      <td>IBM</td>\n",
       "      <td>₹9,08,246</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹23L</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹11,93,390</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>₹xL</td>\n",
       "      <td>₹xCr</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>₹xx,xx,xxx</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>₹xL</td>\n",
       "      <td>₹xxL</td>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹x,xx,xxx</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>₹xL</td>\n",
       "      <td>₹xxL</td>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>₹xx,xx,xxx</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>₹xL</td>\n",
       "      <td>₹xxL</td>\n",
       "      <td>Optum</td>\n",
       "      <td>₹xx,xx,xxx</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>₹xxL</td>\n",
       "      <td>₹xxL</td>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>₹xx,xx,xxx</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>₹xL</td>\n",
       "      <td>₹xxL</td>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>₹x,xx,xxx</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>₹xL</td>\n",
       "      <td>₹xxL</td>\n",
       "      <td>EXL Service</td>\n",
       "      <td>₹xx,xx,xxx</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Minimum Salary Maximum Salary               Company Name Average Salary  \\\n",
       "0            ₹4L           ₹13L  Tata Consultancy Services      ₹6,28,021   \n",
       "1            ₹1L           ₹28L                        IBM      ₹9,08,246   \n",
       "2            ₹6L           ₹23L                  Accenture     ₹11,93,390   \n",
       "3            ₹xL           ₹xCr                  Delhivery     ₹xx,xx,xxx   \n",
       "4            ₹xL           ₹xxL         Ericsson-Worldwide      ₹x,xx,xxx   \n",
       "5            ₹xL           ₹xxL         UnitedHealth Group     ₹xx,xx,xxx   \n",
       "6            ₹xL           ₹xxL                      Optum     ₹xx,xx,xxx   \n",
       "7           ₹xxL           ₹xxL     Optum Global Solutions     ₹xx,xx,xxx   \n",
       "8            ₹xL           ₹xxL         Valiance Solutions      ₹x,xx,xxx   \n",
       "9            ₹xL           ₹xxL                EXL Service     ₹xx,xx,xxx   \n",
       "\n",
       "  Company Rating  \n",
       "0            3.9  \n",
       "1            3.9  \n",
       "2            4.1  \n",
       "3            3.7  \n",
       "4              4  \n",
       "5            3.7  \n",
       "6            3.7  \n",
       "7            3.9  \n",
       "8            4.2  \n",
       "9            3.6  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code to get the minimum salary\n",
    "min_sal = driver.find_elements_by_xpath('//div[@class=\"d-flex mt-xxsm css-79elbk epuxyqn0\"]//p')\n",
    "minsal=[]\n",
    "for i in min_sal[:20]:\n",
    "    minsal.append(i.text)\n",
    "minisal=[]\n",
    "for i in range(0, len(minsal), 2):\n",
    "    minisal.append(minsal[i])\n",
    "\n",
    "# code to get the maximum salary\n",
    "maxisal=[]\n",
    "for i in range(1, len(minsal), 2):\n",
    "    maxisal.append(minsal[i])\n",
    "    \n",
    "# code to get the company names\n",
    "com_name = driver.find_elements_by_xpath('//a[@class=\"css-f3vw95 e1aj7ssy3\"]')\n",
    "cname = []\n",
    "for i in com_name[:10]:\n",
    "    cname.append(i.text)\n",
    "\n",
    "# code to get the average salary\n",
    "avg_sal = driver.find_elements_by_xpath('//div[@class=\"col-12 col-lg-4 px-lg-0 d-flex align-items-baseline\"]//h3')\n",
    "avgsal = []\n",
    "for i in avg_sal[:10]:\n",
    "    avgsal.append(i.text)\n",
    "    \n",
    "# code to get the rating of the company\n",
    "com_rating = driver.find_elements_by_xpath('//span[@class=\"m-0 css-kyx745\"]')\n",
    "crating = []\n",
    "for i in com_rating[:10]:\n",
    "    crating.append(i.text)\n",
    "    \n",
    "\n",
    "# creating the data frame now\n",
    "df = pd.DataFrame({})\n",
    "df['Minimum Salary']=minisal\n",
    "df['Maximum Salary']=maxisal\n",
    "df['Company Name']=cname\n",
    "df['Average Salary']=avgsal\n",
    "df['Company Rating']=crating\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to flipkart webpage by url https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "3. after that you will reach to a webpage having a lot of sunglasses. From this page you can scrap the required data as usual.\n",
    "4. after scraping data from the first page, go to the “Next” Button at the bottom of the page , then click on it\n",
    "5. Now scrape data from this page as usual\n",
    "6. repeat this until you get data for 100 sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the web driver\n",
    "driver=webdriver.Chrome(executable_path=\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "# getting the flipkart shopping site url on the web driver\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the search bar\n",
    "search_bar=driver.find_element_by_class_name(\"_3704LK\")\n",
    "search_bar.send_keys('sunglasses')\n",
    "\n",
    "time.sleep(2)\n",
    "#locating the button and clicking it toh search for sunglasses\n",
    "button=driver.find_element_by_class_name('L0Z3Pu')\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to extract brand details\n",
    "prod_brand = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "brand = []\n",
    "for i in prod_brand:\n",
    "    brand.append(i.text)\n",
    "\n",
    "# code to extract product description\n",
    "prod_descriptn = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "descriptn = []\n",
    "for i in prod_descriptn:\n",
    "    try:\n",
    "        descriptn.append(i.text)\n",
    "    except:\n",
    "        descriptn.appendend(\"No description available\")\n",
    "\n",
    "# code to extract price of the product\n",
    "prod_price = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "price = []\n",
    "for i in prod_price:\n",
    "    price.append(i.text)\n",
    "\n",
    "# code to extract the discount percentage\n",
    "prod_discount = driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]//span')\n",
    "discount = []\n",
    "for i in prod_discount:\n",
    "    discount.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to click on the next button for page 2\n",
    "search_btn1 = driver.find_element_by_xpath('/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]')\n",
    "search_btn1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to extract brand details\n",
    "prod_brand = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "for i in prod_brand:\n",
    "    brand.append(i.text)\n",
    "\n",
    "# code to extract product description\n",
    "prod_descriptn = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "for i in prod_descriptn:\n",
    "    try:\n",
    "        descriptn.append(i.text)\n",
    "    except:\n",
    "        descriptn.appendend(\"No description available\")\n",
    "\n",
    "# code to extract price of the product\n",
    "prod_price = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "for i in prod_price:\n",
    "    price.append(i.text)\n",
    "\n",
    "# code to extract the discount percentage\n",
    "prod_discount = driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]//span')\n",
    "for i in prod_discount:\n",
    "    discount.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to click on the next button for page 3\n",
    "search_btn2 = driver.find_element_by_xpath('/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]')\n",
    "search_btn2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of columns: 120 109 120 120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sunglasses Brand</th>\n",
       "      <th>Sunglasses Description</th>\n",
       "      <th>Sunglasses Price</th>\n",
       "      <th>Sunglasses Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I Flash</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Rectangular...</td>\n",
       "      <td>₹137</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I Flash</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹132</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹198</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹295</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹284</td>\n",
       "      <td>89% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>UV Protection Round Sunglasses (50)</td>\n",
       "      <td>₹374</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Cruze</td>\n",
       "      <td>UV Protection Cat-eye Sunglasses (60)</td>\n",
       "      <td>₹499</td>\n",
       "      <td>61% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Over-sized Sunglasses (60)</td>\n",
       "      <td>₹331</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Badfella</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹269</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection Shield Sunglasses (Free Size)</td>\n",
       "      <td>₹1,415</td>\n",
       "      <td>29% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sunglasses Brand                             Sunglasses Description  \\\n",
       "0             I Flash  UV Protection, Polarized, Mirrored Rectangular...   \n",
       "1             I Flash                UV Protection Round Sunglasses (54)   \n",
       "2   SHAAH COLLECTIONS  Mirrored, UV Protection Wayfarer Sunglasses (F...   \n",
       "3           Elligator  UV Protection, Gradient Rectangular Sunglasses...   \n",
       "4      kingsunglasses              UV Protection Aviator Sunglasses (54)   \n",
       "..                ...                                                ...   \n",
       "95             GANSTA                UV Protection Round Sunglasses (50)   \n",
       "96              Cruze              UV Protection Cat-eye Sunglasses (60)   \n",
       "97             PIRASO           UV Protection Over-sized Sunglasses (60)   \n",
       "98           Badfella   UV Protection Rectangular Sunglasses (Free Size)   \n",
       "99      VINCENT CHASE        UV Protection Shield Sunglasses (Free Size)   \n",
       "\n",
       "   Sunglasses Price Sunglasses Discount  \n",
       "0              ₹137             86% off  \n",
       "1              ₹132             86% off  \n",
       "2              ₹198             88% off  \n",
       "3              ₹295             88% off  \n",
       "4              ₹284             89% off  \n",
       "..              ...                 ...  \n",
       "95             ₹374             81% off  \n",
       "96             ₹499             61% off  \n",
       "97             ₹331             79% off  \n",
       "98             ₹269             73% off  \n",
       "99           ₹1,415             29% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code to extract brand details\n",
    "prod_brand = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "for i in prod_brand:\n",
    "    brand.append(i.text)\n",
    "\n",
    "# code to extract product description\n",
    "prod_descriptn = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "for i in prod_descriptn:\n",
    "    try:\n",
    "        descriptn.append(i.text)\n",
    "    except:\n",
    "        descriptn.append(\"No description available\")\n",
    "\n",
    "# code to extract price of the product\n",
    "prod_price = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "for i in prod_price:\n",
    "    price.append(i.text)\n",
    "\n",
    "# code to extract the discount percentage\n",
    "prod_discount = driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]//span')\n",
    "for i in prod_discount:\n",
    "    discount.append(i.text)\n",
    "    \n",
    "# checking the length to get the data frame\n",
    "print(\"Lengths of columns:\", len(brand), len(descriptn), len(price), len(discount))\n",
    "\n",
    "# creating the data frame now\n",
    "df = pd.DataFrame({})\n",
    "df['Sunglasses Brand']=brand[:100]\n",
    "df['Sunglasses Description']=descriptn[:100]\n",
    "df['Sunglasses Price']=price[:100]\n",
    "df['Sunglasses Discount']=discount[:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.\n",
    "When you will open the above link you will reach to the below shown webpage.\n",
    "As shown in the above page you have to scrape the tick marked attributes.\n",
    "These are\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review\n",
    "You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the web driver\n",
    "driver=webdriver.Chrome(executable_path=\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "# getting the flipkart shopping site url on the web driver\n",
    "url = \"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iPhone Rating</th>\n",
       "      <th>iPhone Short Review</th>\n",
       "      <th>iPhone Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>The ultimate performance\\nCamera is superb\\nTh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>I use a Note10+ and have been using both iOS a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>The phone is completely good\\nAs far as camera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>3</td>\n",
       "      <td>Decent product</td>\n",
       "      <td>Everything u ll like it when u use this iPhone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>Can’t beat the software and hardware integrati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   iPhone Rating  iPhone Short Review  \\\n",
       "0              5            Brilliant   \n",
       "1              5       Simply awesome   \n",
       "2              5  Best in the market!   \n",
       "3              5     Perfect product!   \n",
       "4              5            Fabulous!   \n",
       "..           ...                  ...   \n",
       "95             5            Just wow!   \n",
       "96             5    Terrific purchase   \n",
       "97             5              Awesome   \n",
       "98             3       Decent product   \n",
       "99             5              Awesome   \n",
       "\n",
       "                                   iPhone Full Review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   Amazing phone with great cameras and better ba...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "95  The ultimate performance\\nCamera is superb\\nTh...  \n",
       "96  I use a Note10+ and have been using both iOS a...  \n",
       "97  The phone is completely good\\nAs far as camera...  \n",
       "98  Everything u ll like it when u use this iPhone...  \n",
       "99  Can’t beat the software and hardware integrati...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(2)\n",
    "\n",
    "# Creating empty list\n",
    "urls=[]\n",
    "short_review=[]\n",
    "full_review=[]\n",
    "rating=[]\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "#scraping 10 pages url\n",
    "url_1 = driver.find_elements_by_xpath(\"//a[@class='ge-49M _2Kfbh8']\")\n",
    "for i in url_1:\n",
    "    urls.append(i.get_attribute('href'))\n",
    "    \n",
    "url_2 = driver.find_elements_by_xpath(\"//a[@class='ge-49M']\")\n",
    "for i in url_2:\n",
    "    urls.append(i.get_attribute('href'))\n",
    "time.sleep(4)\n",
    "\n",
    "\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    # scraping the number of stars\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='col _2wzgFH K0kLPL']/div[1]/div[1]\"):\n",
    "        rating.append(j.text)\n",
    "    # scraping the short review\n",
    "    for k in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "        short_review.append(k.text)\n",
    "    # scraping the complete review\n",
    "    for l in driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']/div/div\"):\n",
    "        full_review.append(l.text)\n",
    "        \n",
    "        \n",
    "        \n",
    "#Combining all the lists into a single dataframe\n",
    "df = pd.DataFrame({})\n",
    "df['iPhone Rating']=rating\n",
    "df['iPhone Short Review']=short_review\n",
    "df['iPhone Full Review']=full_review[:100]\n",
    "df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %\n",
    "As shown in the below image, you have to scrape the tick marked attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the web driver\n",
    "driver=webdriver.Chrome(executable_path=\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "# getting the flipkart shopping site url on the web driver\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to write sneakers in the search box\n",
    "search_prod = driver.find_element_by_xpath('//input[@class=\"_3704LK\"]')\n",
    "search_prod.send_keys(\"Sneakers\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# code to click on the search button\n",
    "search_btn = driver.find_element_by_xpath('//button[@class=\"L0Z3Pu\"]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = driver.find_elements_by_xpath('//nav[@class=\"yFHi8N\"]//a')\n",
    "\n",
    "# extract all the product search links from the above search result\n",
    "prod_urls=[]\n",
    "for i in url[:5]:\n",
    "    prod_urls.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sneaker Brand</th>\n",
       "      <th>Sneaker Description</th>\n",
       "      <th>Sneaker Price</th>\n",
       "      <th>Sneaker Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Echor</td>\n",
       "      <td>Men's Sneakers Walking Shoes - Lightweight Cla...</td>\n",
       "      <td>₹429</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DUCATI</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,499</td>\n",
       "      <td>59% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹356</td>\n",
       "      <td>64% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Combo Pack Of 4 Casual Shoes Loafer Shoes Snea...</td>\n",
       "      <td>₹474</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Longwalk</td>\n",
       "      <td>Men Boxer Sneakers For Men</td>\n",
       "      <td>₹236</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>DUCATI</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,259</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>LuvShus</td>\n",
       "      <td>Lazy Knit Slip On IDP Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SHOEFLY</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹362</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Zsyto</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹398</td>\n",
       "      <td>69% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Nilatin</td>\n",
       "      <td>luxury fashionable casual shoes Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sneaker Brand                                Sneaker Description  \\\n",
       "0          Echor  Men's Sneakers Walking Shoes - Lightweight Cla...   \n",
       "1         DUCATI                                   Sneakers For Men   \n",
       "2       Magnolia                                   Sneakers For Men   \n",
       "3         BRUTON  Combo Pack Of 4 Casual Shoes Loafer Shoes Snea...   \n",
       "4       Longwalk                         Men Boxer Sneakers For Men   \n",
       "..           ...                                                ...   \n",
       "95        DUCATI                                   Sneakers For Men   \n",
       "96       LuvShus             Lazy Knit Slip On IDP Sneakers For Men   \n",
       "97       SHOEFLY                                   Sneakers For Men   \n",
       "98         Zsyto                                   Sneakers For Men   \n",
       "99       Nilatin   luxury fashionable casual shoes Sneakers For Men   \n",
       "\n",
       "   Sneaker Price Sneaker Discount  \n",
       "0           ₹429          57% off  \n",
       "1         ₹1,499          59% off  \n",
       "2           ₹356          64% off  \n",
       "3           ₹474          86% off  \n",
       "4           ₹236          52% off  \n",
       "..           ...              ...  \n",
       "95        ₹1,259          65% off  \n",
       "96          ₹449          55% off  \n",
       "97          ₹362          70% off  \n",
       "98          ₹398          69% off  \n",
       "99          ₹449          65% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code to extract brand details\n",
    "brand = []\n",
    "for i in prod_urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        prod_brand = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "        for j in prod_brand:\n",
    "            brand.append(j.text)\n",
    "    except:\n",
    "        brand.append(\"---\")\n",
    "\n",
    "# code to extract product description\n",
    "descriptn = []\n",
    "for i in prod_urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        prod_descriptn = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "        for j in prod_descriptn:\n",
    "            descriptn.append(j.text)\n",
    "    except:\n",
    "        descriptn.append(\"---\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# code to extract price of the product\n",
    "price = []\n",
    "for i in prod_urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        prod_price = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "        for j in prod_price:\n",
    "            price.append(j.text)\n",
    "    except:\n",
    "        price.append(\"---\")\n",
    "        \n",
    "time.sleep(2)\n",
    "        \n",
    "# code to extract the discount percentage\n",
    "discount = []\n",
    "for i in prod_urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        prod_discount = driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]//span')\n",
    "        for j in prod_discount:\n",
    "            discount.append(j.text)\n",
    "    except:\n",
    "        discount.append(\"---\")\n",
    "        \n",
    "time.sleep(2)\n",
    "\n",
    "# creating the data frame\n",
    "df = pd.DataFrame({})\n",
    "df['Sneaker Brand']=brand[:100]\n",
    "df['Sneaker Description']=descriptn[:100]\n",
    "df['Sneaker Price']=price[:100]\n",
    "df['Sneaker Discount']=discount[:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, as shown in the below image And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe. Please note: Everything should done through code even the filtering for sneakers as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the web driver\n",
    "driver=webdriver.Chrome(executable_path=\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "# getting the myntra shoes site url on the web driver\n",
    "url = \"https://www.myntra.com/shoes\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to click on the color filter for \"Black\"\n",
    "color_filter = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div')\n",
    "color_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to click on the price filter for \"Rs. 6935 to 13621\" as “Rs. 6649 to Rs. 13099” is not available\n",
    "price_filter = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div')\n",
    "price_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = driver.find_elements_by_xpath('//li[@class=\"pagination-number\"]//a')\n",
    "\n",
    "# extract all the shoe links from the above search result\n",
    "shoe_urls=[]\n",
    "for i in url[:5]:\n",
    "    shoe_urls.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to extract shoe brand details\n",
    "sbrand = []\n",
    "for i in shoe_urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        shoe_brand = driver.find_elements_by_xpath('//div[@class=\"product-productMetaInfo\"]//h3')\n",
    "        for j in shoe_brand:\n",
    "            sbrand.append(j.text)\n",
    "    except:\n",
    "        sbrand.append(\"---\")\n",
    "\n",
    "# code to extract shoe description\n",
    "sdescriptn = []\n",
    "for i in shoe_urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        shoe_descriptn = driver.find_elements_by_xpath('//div[@class=\"product-productMetaInfo\"]//h4')\n",
    "        for j in shoe_descriptn:\n",
    "            sdescriptn.append(j.text)\n",
    "    except:\n",
    "        sdescriptn.append(\"---\")\n",
    "description=[]\n",
    "for i in range(0, len(sdescriptn), 2):\n",
    "    description.append(sdescriptn[i])\n",
    "\n",
    "# code to extract shoe price\n",
    "sprice = []\n",
    "for i in shoe_urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        shoe_price = driver.find_elements_by_xpath('//span[@class=\"product-discountedPrice\"]')\n",
    "        for j in shoe_price:\n",
    "            sprice.append(j.text)\n",
    "    except:\n",
    "        sprice.append(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shoe Brand</th>\n",
       "      <th>Shoe Description</th>\n",
       "      <th>Shoe Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Women GlideRide Running Shoes</td>\n",
       "      <td>Rs. 11199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASICS</td>\n",
       "      <td>Men Solid Leather Formal Derbys</td>\n",
       "      <td>Rs. 6993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Leather Formal Loafers</td>\n",
       "      <td>Rs. 7006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Women Leather Heeled Boots</td>\n",
       "      <td>Rs. 7693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Women Solid Leather Gladiators</td>\n",
       "      <td>Rs. 7039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KIPRUN By Decathlon</td>\n",
       "      <td>Women Running Shoes</td>\n",
       "      <td>Rs. 7773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Women RS-Curve City Sneakers</td>\n",
       "      <td>Rs. 10399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PUMA Motorsport</td>\n",
       "      <td>Women BMW M Motorsport Shoes</td>\n",
       "      <td>Rs. 7499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Women Fuse Moto Training Shoes</td>\n",
       "      <td>Rs. 9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Women Liberate NITRO Running</td>\n",
       "      <td>Rs. 7199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Men Leather Sneakers</td>\n",
       "      <td>Rs. 6993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Men Wingtip Oxford Sneakers</td>\n",
       "      <td>Rs. 10493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Men GENERATION ZEROGRAND STITCHLITE</td>\n",
       "      <td>Rs. 7192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Leather Sneakers</td>\n",
       "      <td>Rs. 11242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>VIONIC</td>\n",
       "      <td>Men Textured Sneakers</td>\n",
       "      <td>Rs. 7992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Textured Leather Loafers</td>\n",
       "      <td>Rs. 7192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Solid Leather Loafers</td>\n",
       "      <td>Rs. 8792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Textured Leather Loafers</td>\n",
       "      <td>Rs. 7343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Kalenji By Decathlon</td>\n",
       "      <td>Men KD500 Running Shoe</td>\n",
       "      <td>Rs. 9513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 9975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women Air Zoom Running Shoes</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PUMA Motorsport</td>\n",
       "      <td>Unisex BMW MMS RS-FastSneakers</td>\n",
       "      <td>Rs. 7499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Leather Formal Slip-Ons</td>\n",
       "      <td>Rs. 11305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Jamming 2.0 Running Shoes</td>\n",
       "      <td>Rs. 10399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Men Tassel Leather Loafer</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ASICS</td>\n",
       "      <td>Men Black Running Sports Shoes</td>\n",
       "      <td>Rs. 9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ASICS</td>\n",
       "      <td>Men Tennis Shoes</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ASICS</td>\n",
       "      <td>Men GEL-GLYDE 3 MX Running</td>\n",
       "      <td>Rs. 9975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Ruosh</td>\n",
       "      <td>Men Black Walking Shoes</td>\n",
       "      <td>Rs. 7799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Men Walking Shoes</td>\n",
       "      <td>Rs. 9099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Women Leather Heeled Boots</td>\n",
       "      <td>Rs. 7400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Women Solid Leather Heels</td>\n",
       "      <td>Rs. 6993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Women Leather Heeled Boots</td>\n",
       "      <td>Rs. 7693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Women Heeled Boots</td>\n",
       "      <td>Rs. 6993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Women Leather Pumps</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Kenneth Cole</td>\n",
       "      <td>Women Peep Toe Heels</td>\n",
       "      <td>Rs. 8253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Men Leather Formal Slip-Ons</td>\n",
       "      <td>Rs. 7199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Textured Leather Loafers</td>\n",
       "      <td>Rs. 7199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Solid Sneakers</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Leather Flat Boots</td>\n",
       "      <td>Rs. 11999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Women Open Toe Flats</td>\n",
       "      <td>Rs. 9599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Men Leather Driving Shoes</td>\n",
       "      <td>Rs. 8953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Solid Leather Formal Derbys</td>\n",
       "      <td>Rs. 7192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Florsheim</td>\n",
       "      <td>Men Leather Formal Loafers</td>\n",
       "      <td>Rs. 8249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Men Suede Sneakers</td>\n",
       "      <td>Rs. 7693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Men Solid Leather Formal Monks</td>\n",
       "      <td>Rs. 7499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Women Leather Pumps</td>\n",
       "      <td>Rs. 8094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>PUMA Motorsport</td>\n",
       "      <td>Unisex Mercedes F1 Sneakers</td>\n",
       "      <td>Rs. 7206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Unisex Pacer Future Sneakers</td>\n",
       "      <td>Rs. 9513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Unisex Mirage Sport Trainers</td>\n",
       "      <td>Rs. 7199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men ZOOM SPAN 3 Running Shoes</td>\n",
       "      <td>Rs. 8399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Vomero 16 Running Shoes</td>\n",
       "      <td>Rs. 7693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "      <td>Rs. 9099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Shoe Brand                     Shoe Description Shoe Price\n",
       "0                Saint G        Women GlideRide Running Shoes  Rs. 11199\n",
       "1                  ASICS      Men Solid Leather Formal Derbys   Rs. 6993\n",
       "2              J.FONTINI           Men Leather Formal Loafers   Rs. 7006\n",
       "3                Saint G           Women Leather Heeled Boots   Rs. 7693\n",
       "4   Heel & Buckle London       Women Solid Leather Gladiators   Rs. 7039\n",
       "5    KIPRUN By Decathlon                  Women Running Shoes   Rs. 7773\n",
       "6                   Puma         Women RS-Curve City Sneakers  Rs. 10399\n",
       "7        PUMA Motorsport         Women BMW M Motorsport Shoes   Rs. 7499\n",
       "8                   Puma       Women Fuse Moto Training Shoes   Rs. 9093\n",
       "9                   Puma         Women Liberate NITRO Running   Rs. 7199\n",
       "10  Heel & Buckle London                 Men Leather Sneakers   Rs. 6993\n",
       "11             Cole Haan          Men Wingtip Oxford Sneakers  Rs. 10493\n",
       "12             Cole Haan  Men GENERATION ZEROGRAND STITCHLITE   Rs. 7192\n",
       "13             Cole Haan                     Leather Sneakers  Rs. 11242\n",
       "14                VIONIC                Men Textured Sneakers   Rs. 7992\n",
       "15             J.FONTINI         Men Textured Leather Loafers   Rs. 7192\n",
       "16             J.FONTINI            Men Solid Leather Loafers   Rs. 8792\n",
       "17             J.FONTINI         Men Textured Leather Loafers   Rs. 7343\n",
       "18  Kalenji By Decathlon               Men KD500 Running Shoe   Rs. 9513\n",
       "19                  Puma                    Men Running Shoes   Rs. 9975\n",
       "20                  Nike         Women Air Zoom Running Shoes   Rs. 7999\n",
       "21       PUMA Motorsport       Unisex BMW MMS RS-FastSneakers   Rs. 7499\n",
       "22                  Geox          Men Leather Formal Slip-Ons  Rs. 11305\n",
       "23                  Puma        Men Jamming 2.0 Running Shoes  Rs. 10399\n",
       "24  Heel & Buckle London            Men Tassel Leather Loafer   Rs. 7999\n",
       "25                 ASICS       Men Black Running Sports Shoes   Rs. 9093\n",
       "26                 ASICS                     Men Tennis Shoes   Rs. 6999\n",
       "27                 ASICS           Men GEL-GLYDE 3 MX Running   Rs. 9975\n",
       "28                 Ruosh              Men Black Walking Shoes   Rs. 7799\n",
       "29               Bugatti                    Men Walking Shoes   Rs. 9099\n",
       "30               Bugatti           Women Leather Heeled Boots   Rs. 7400\n",
       "31  Heel & Buckle London            Women Solid Leather Heels   Rs. 6993\n",
       "32               Saint G           Women Leather Heeled Boots   Rs. 7693\n",
       "33               Saint G                   Women Heeled Boots   Rs. 6993\n",
       "34               Saint G                  Women Leather Pumps   Rs. 6999\n",
       "35          Kenneth Cole                 Women Peep Toe Heels   Rs. 8253\n",
       "36  Heel & Buckle London          Men Leather Formal Slip-Ons   Rs. 7199\n",
       "37                  Geox         Men Textured Leather Loafers   Rs. 7199\n",
       "38             J.FONTINI                   Men Solid Sneakers   Rs. 6999\n",
       "39                  Geox               Men Leather Flat Boots  Rs. 11999\n",
       "40                  Geox                 Women Open Toe Flats   Rs. 9599\n",
       "41             Cole Haan            Men Leather Driving Shoes   Rs. 8953\n",
       "42                  Geox      Men Solid Leather Formal Derbys   Rs. 7192\n",
       "43             Florsheim           Men Leather Formal Loafers   Rs. 8249\n",
       "44        Tommy Hilfiger                   Men Suede Sneakers   Rs. 7693\n",
       "45  Heel & Buckle London       Men Solid Leather Formal Monks   Rs. 7499\n",
       "46  Heel & Buckle London                  Women Leather Pumps   Rs. 8094\n",
       "47       PUMA Motorsport          Unisex Mercedes F1 Sneakers   Rs. 7206\n",
       "48                  Puma         Unisex Pacer Future Sneakers   Rs. 9513\n",
       "49                  Puma         Unisex Mirage Sport Trainers   Rs. 7199\n",
       "50             J.FONTINI        Men ZOOM SPAN 3 Running Shoes   Rs. 8399\n",
       "51                  Nike          Men Vomero 16 Running Shoes   Rs. 7693\n",
       "52                  Nike    Men Solid Leather Formal Slip-Ons   Rs. 9099"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the data frame\n",
    "df = pd.DataFrame({})\n",
    "df['Shoe Brand']=sbrand[:53]\n",
    "df['Shoe Description']=description[:53]\n",
    "df['Shoe Price']=sprice[:53]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10: Go to webpage https://www.amazon.in/Enter “Laptop” in the search field and then click the search icon.Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” After setting the filters scrape first 10 laptops data.You have to scrape 3 attributes for each laptop:\n",
    "\n",
    "1.title\n",
    "\n",
    "2.Ratings\n",
    "\n",
    "3.Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the web driver\n",
    "driver=webdriver.Chrome(executable_path=\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "# getting the amazon shopping site url on the web driver\n",
    "url = \"https://www.amazon.in/\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the search bar\n",
    "search_bar = driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "search_bar.clear()                                               \n",
    "search_bar.send_keys(\"laptops\") \n",
    "\n",
    "#clicking on the search button\n",
    "search_button = driver.find_element_by_xpath('//span[@id=\"nav-search-submit-text\"]')      \n",
    "search_button.click()    \n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the core i7 filter\n",
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i7':\n",
    "        i.click()\n",
    "        break\n",
    "        \n",
    "#locating the core i9 filter\n",
    "filter_button1=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button1:\n",
    "    if i.text=='Intel Core i9':\n",
    "        i.click()\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laptop Title</th>\n",
       "      <th>Laptop Rating</th>\n",
       "      <th>Laptop Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP Envy 11th Gen Core i7 Processor 13.3-inch (...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>1,23,350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>57,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo IdeaPad S540 11th Gen Intel Core i7 13....</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>77,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS TUF Dash F15 (2021), 15.6-inch (39.62 cms...</td>\n",
       "      <td>3.0 out of 5 stars</td>\n",
       "      <td>85,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS TUF Dash F15 (2021), 15.6-inch (39.62 cms...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Pavilion 13(2021) 11th Gen Intel Core i7 La...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>92,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel Core i7 13.3” (33....</td>\n",
       "      <td>3.7 out of 5 stars</td>\n",
       "      <td>1,07,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASUS ROG G703GI-E5148T 17.3\" (43.94 cms) FHD 1...</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "      <td>5,56,524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo IdeaPad Gaming 3 Intel Core i7 10th Gen...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>73,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel i7 Core 13.3” (33....</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>92,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Laptop Title       Laptop Rating  \\\n",
       "0  HP Envy 11th Gen Core i7 Processor 13.3-inch (...  4.1 out of 5 stars   \n",
       "1  Mi Notebook Horizon Edition 14 Intel Core i7-1...  4.2 out of 5 stars   \n",
       "2  Lenovo IdeaPad S540 11th Gen Intel Core i7 13....  4.3 out of 5 stars   \n",
       "3  ASUS TUF Dash F15 (2021), 15.6-inch (39.62 cms...  3.0 out of 5 stars   \n",
       "4  ASUS TUF Dash F15 (2021), 15.6-inch (39.62 cms...  5.0 out of 5 stars   \n",
       "5  HP Pavilion 13(2021) 11th Gen Intel Core i7 La...  4.1 out of 5 stars   \n",
       "6  Fujitsu UH-X 11th Gen Intel Core i7 13.3” (33....  3.7 out of 5 stars   \n",
       "7  ASUS ROG G703GI-E5148T 17.3\" (43.94 cms) FHD 1...  4.4 out of 5 stars   \n",
       "8  Lenovo IdeaPad Gaming 3 Intel Core i7 10th Gen...  4.2 out of 5 stars   \n",
       "9  Fujitsu UH-X 11th Gen Intel i7 Core 13.3” (33....  4.0 out of 5 stars   \n",
       "\n",
       "  Laptop Price  \n",
       "0     1,23,350  \n",
       "1       57,990  \n",
       "2       77,990  \n",
       "3       85,990  \n",
       "4       84,990  \n",
       "5       92,990  \n",
       "6     1,07,990  \n",
       "7     5,56,524  \n",
       "8       73,990  \n",
       "9       92,990  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the empty list\n",
    "Title=[]\n",
    "Rating=[]\n",
    "Price=[]\n",
    "\n",
    "#Scraping Titles\n",
    "titles=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "for i in titles[:10]:\n",
    "    Title.append(i.text)\n",
    "    \n",
    "    \n",
    "#scraping Price\n",
    "prices=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "for i in prices[:10]:\n",
    "    Price.append(i.text)\n",
    "\n",
    "# code to extract laptop rating\n",
    "lap_rating = driver.find_elements_by_class_name(\"a-icon-alt\")\n",
    "for i in lap_rating[:10]:\n",
    "    Rating.append(i.get_attribute('textContent'))\n",
    "        \n",
    "# creating the data frame now\n",
    "df = pd.DataFrame({})\n",
    "df['Laptop Title']=Title\n",
    "df['Laptop Rating']=Rating\n",
    "df['Laptop Price']=Price\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
