{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Assignment with BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Write a python program to display all the header tags from ‘en.wikipedia.org/wiki/Main_Page’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['h1 Main Page',\n",
       " \"h2 From today's featured article\",\n",
       " 'h2 Did you know\\xa0...',\n",
       " 'h2 In the news',\n",
       " 'h2 On this day',\n",
       " \"h2 Today's featured picture\",\n",
       " 'h2 Other areas of Wikipedia',\n",
       " \"h2 Wikipedia's sister projects\",\n",
       " 'h2 Wikipedia languages',\n",
       " 'h2 Navigation menu',\n",
       " 'h3 Personal tools',\n",
       " 'h3 Namespaces',\n",
       " 'h3 Variants',\n",
       " 'h3 Views',\n",
       " 'h3 More',\n",
       " 'h3 Search',\n",
       " 'h3 Navigation',\n",
       " 'h3 Contribute',\n",
       " 'h3 Tools',\n",
       " 'h3 Print/export',\n",
       " 'h3 In other projects',\n",
       " 'h3 Languages']"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# send get request to the webpage server to get the source code of the page\n",
    "\n",
    "wiki_page = requests.get(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
    "print(wiki_page)\n",
    "\n",
    "# to get the page content\n",
    "soup_wiki = BeautifulSoup(wiki_page.content)\n",
    "\n",
    "#to extract the header details\n",
    "\n",
    "headers = soup_wiki.find_all([\"h1\",\"h2\",\"h3\",\"h4\",\"h5\",\"h6\"])\n",
    "header_tags = []\n",
    "\n",
    "for i in headers:\n",
    "    header_tags.append(i.name+\" \"+i.text.strip())\n",
    "\n",
    "# to print all the header details\n",
    "header_tags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of release)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of the movie</th>\n",
       "      <th>Rating of the movie</th>\n",
       "      <th>Year of release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.3</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(1974)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1959)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Clockwork Orange</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1971)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Snatch</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Le fabuleux destin d'Amélie Poulain</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Kid</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1921)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Name of the movie  Rating of the movie Year of release\n",
       "0              The Shawshank Redemption                  9.3          (1994)\n",
       "1                         The Godfather                  9.2          (1972)\n",
       "2                The Godfather: Part II                  9.0          (1974)\n",
       "3                       The Dark Knight                  9.0          (2008)\n",
       "4                          12 Angry Men                  9.0          (1957)\n",
       "..                                  ...                  ...             ...\n",
       "95                   North by Northwest                  8.3          (1959)\n",
       "96                   A Clockwork Orange                  8.3          (1971)\n",
       "97                               Snatch                  8.3          (2000)\n",
       "98  Le fabuleux destin d'Amélie Poulain                  8.3          (2001)\n",
       "99                              The Kid                  8.3          (1921)\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "\n",
    "imdb_100_movies_page = requests.get(\"https://www.imdb.com/list/ls091520106/\")\n",
    "print(imdb_100_movies_page)\n",
    "\n",
    "#to see the page content\n",
    "soup_imdb = BeautifulSoup(imdb_100_movies_page.content)\n",
    "\n",
    "# to get the top Movies name\n",
    "\n",
    "imdb_100_movies = soup_imdb.find_all(\"h3\",class_=\"lister-item-header\")\n",
    "\n",
    "movie_names = []\n",
    "for i in imdb_100_movies:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        movie_names.append(j.text.replace(\"\\n\",\" \"))\n",
    "movie_names\n",
    "\n",
    "# to get the Year of release\n",
    "imdb_year = soup_imdb.find_all(\"span\",class_=\"lister-item-year text-muted unbold\")\n",
    "\n",
    "movie_year = []\n",
    "for i in imdb_year:\n",
    "    movie_year.append(i.text)\n",
    "movie_year\n",
    "\n",
    "# to get the IMDB Rating\n",
    "imdb_rating = soup_imdb.find_all(\"div\", class_=\"ipl-rating-star small\")\n",
    "\n",
    "rating = []\n",
    "for i in imdb_rating:\n",
    "    rating.append(float(i.text))\n",
    "rating\n",
    "\n",
    "# to Make data frame of top 100 movies on IMDB\n",
    "df_imdb=pd.DataFrame({})\n",
    "df_imdb['Name of the movie']=movie_names\n",
    "df_imdb['Rating of the movie']=rating\n",
    "df_imdb['Year of release']=movie_year\n",
    "df_imdb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year of release)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie name</th>\n",
       "      <th>Year of release</th>\n",
       "      <th>IMDB rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rang De Basanti</td>\n",
       "      <td>2006</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 Idiots</td>\n",
       "      <td>2009</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Taare Zameen Par</td>\n",
       "      <td>2007</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dil Chahta Hai</td>\n",
       "      <td>2001</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Swades: We, the People</td>\n",
       "      <td>2004</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Wake Up Sid</td>\n",
       "      <td>2009</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Rangeela</td>\n",
       "      <td>1995</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Shatranj Ke Khilari</td>\n",
       "      <td>1977</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Pyaar Ka Punchnama</td>\n",
       "      <td>2011</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Ek Hasina Thi</td>\n",
       "      <td>2004</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Movie name Year of release  IMDB rating\n",
       "0          Rang De Basanti            2006          8.1\n",
       "1                 3 Idiots            2009          8.4\n",
       "2         Taare Zameen Par            2007          8.4\n",
       "3           Dil Chahta Hai            2001          8.1\n",
       "4   Swades: We, the People            2004          8.2\n",
       "..                     ...             ...          ...\n",
       "95             Wake Up Sid            2009          7.6\n",
       "96                Rangeela            1995          7.5\n",
       "97     Shatranj Ke Khilari            1977          7.6\n",
       "98      Pyaar Ka Punchnama            2011          7.6\n",
       "99           Ek Hasina Thi            2004          7.5\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.imdb.com/list/ls009997493/\"\n",
    "page = requests.get(url)\n",
    "print(page)\n",
    "\n",
    "# to check the page content\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "# to get the top 100 Indian Movies name\n",
    "name = soup.find_all(\"h3\", class_=\"lister-item-header\")\n",
    "\n",
    "# to get the text from movie name web elements\n",
    "movies_name = [] #empty list\n",
    "for i in name:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        movies_name.append(j.text)\n",
    "\n",
    "\n",
    "# Year of release\n",
    "year = soup.find_all(\"span\",class_=\"lister-item-year text-muted unbold\")\n",
    "year_of_release = [] #empty list\n",
    "\n",
    "for i in year:\n",
    "    a=i.text.replace('(','')\n",
    "    year_of_release.append(a.replace(')','')) \n",
    "    \n",
    "\n",
    "# IMDB Rating\n",
    "rating = soup.find_all(\"div\",class_=\"ipl-rating-star small\")\n",
    "\n",
    "# scrape text from rating web element\n",
    "IMDB_rating = [] #empty list\n",
    "for i in rating:\n",
    "      IMDB_rating.append(float(i.text))\n",
    "\n",
    "        \n",
    "# to Make data frame of IMDB top 100 Indian movies\n",
    "indian_top_100=pd.DataFrame({})\n",
    "indian_top_100['Movie name']=movies_name\n",
    "indian_top_100['Year of release']=year_of_release\n",
    "indian_top_100['IMDB rating']=IMDB_rating\n",
    "indian_top_100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Write a python program to scrap book name, author name, genre and book review of any 5 books from\n",
    "‘www.bookpage.com’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>GENRE</th>\n",
       "      <th>REVIEW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gone for Good</td>\n",
       "      <td>Gone for Good</td>\n",
       "      <td>Mystery &amp; Suspense</td>\n",
       "      <td>Annalisa Vega probably shouldn’t be investigat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Autumn Leaves, 1922</td>\n",
       "      <td>Autumn Leaves, 1922</td>\n",
       "      <td>Mystery</td>\n",
       "      <td>Phryne Fisher fans will fall in love with Kiki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Turnout</td>\n",
       "      <td>The Turnout</td>\n",
       "      <td>Mystery &amp; Suspense</td>\n",
       "      <td>Early in The Turnout, the beautifully dark sus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clark and Division</td>\n",
       "      <td>Clark and Division</td>\n",
       "      <td>Mystery</td>\n",
       "      <td>The grief of the World War II-era Japanese com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Good Day for Chardonnay</td>\n",
       "      <td>A Good Day for Chardonnay</td>\n",
       "      <td>Historical Mystery</td>\n",
       "      <td>Readers who like their murder mysteries to hav...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        NAME                     AUTHOR               GENRE  \\\n",
       "0              Gone for Good              Gone for Good  Mystery & Suspense   \n",
       "1        Autumn Leaves, 1922        Autumn Leaves, 1922             Mystery   \n",
       "2                The Turnout                The Turnout  Mystery & Suspense   \n",
       "3         Clark and Division         Clark and Division             Mystery   \n",
       "4  A Good Day for Chardonnay  A Good Day for Chardonnay  Historical Mystery   \n",
       "\n",
       "                                              REVIEW  \n",
       "0  Annalisa Vega probably shouldn’t be investigat...  \n",
       "1  Phryne Fisher fans will fall in love with Kiki...  \n",
       "2  Early in The Turnout, the beautifully dark sus...  \n",
       "3  The grief of the World War II-era Japanese com...  \n",
       "4  Readers who like their murder mysteries to hav...  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://bookpage.com/reviews?book_genre=mystery_suspense&page=1\"\n",
    "page = requests.get(url)\n",
    "print(page)\n",
    "\n",
    "soup_book = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "#to scrape book name\n",
    "\n",
    "book_name = soup_book.find_all(\"h4\", class_=\"italic\")\n",
    "Book = []\n",
    "for i in book_name:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        Book.append(j.text.replace(\"\\n\",\" \").replace(\"★\", \" \"))\n",
    "\n",
    "#to scrape author name\n",
    "\n",
    "author_book = soup_book.find_all(\"h4\",class_=\"italic\")\n",
    "author = []\n",
    "for i in author_book:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        author.append(j.text.replace(\"\\n\",\" \").replace(\"★\", \" \"))\n",
    "        \n",
    "#Scraping the genre of the book\n",
    "\n",
    "genre_book = soup_book.find_all(\"p\", class_= \"genre-links hidden-phone\")\n",
    "genre = []\n",
    "for i in genre_book:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        genre.append(j.text)\n",
    "        \n",
    "#Scraping the review of the books\n",
    "\n",
    "review_book = soup_book.find_all(\"p\", class_= \"excerpt\")\n",
    "review = []\n",
    "for i in review_book:\n",
    "    for j in i.find_all(\"p\"):\n",
    "        review.append(j.text)\n",
    "        \n",
    "# to Make data frame of Book Name,Author,Genre and Review        \n",
    "BOOK=pd.DataFrame({})\n",
    "BOOK[\"NAME\"]=Book[:5]\n",
    "BOOK[\"AUTHOR\"]=author[:5]\n",
    "BOOK[\"GENRE\"]= genre[:5]\n",
    "BOOK[\"REVIEW\"]= review[:5]\n",
    "BOOK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEAM</th>\n",
       "      <th>MATCHES</th>\n",
       "      <th>POINTS</th>\n",
       "      <th>RATING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>17</td>\n",
       "      <td>2,054</td>\n",
       "      <td>121              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>32</td>\n",
       "      <td>3,793</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>28</td>\n",
       "      <td>3,244</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>32</td>\n",
       "      <td>3,624</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>22</td>\n",
       "      <td>2,267</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>27</td>\n",
       "      <td>2,524</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>29</td>\n",
       "      <td>2,639</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>30</td>\n",
       "      <td>2,523</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>29</td>\n",
       "      <td>2,303</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>17</td>\n",
       "      <td>1,054</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TEAM MATCHES POINTS  \\\n",
       "0   New Zealand      17  2,054   \n",
       "1       England      32  3,793   \n",
       "2     Australia      28  3,244   \n",
       "3         India      32  3,624   \n",
       "4  South Africa      22  2,267   \n",
       "5      Pakistan      27  2,524   \n",
       "6    Bangladesh      29  2,639   \n",
       "7   West Indies      30  2,523   \n",
       "8     Sri Lanka      29  2,303   \n",
       "9   Afghanistan      17  1,054   \n",
       "\n",
       "                                              RATING  \n",
       "0                               121              ...  \n",
       "1                                                119  \n",
       "2                                                116  \n",
       "3                                                113  \n",
       "4                                                103  \n",
       "5                                                 93  \n",
       "6                                                 91  \n",
       "7                                                 84  \n",
       "8                                                 79  \n",
       "9                                                 62  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\"\n",
    "page = requests.get(url)\n",
    "print(page)\n",
    "\n",
    "#parse the HTML\n",
    "soup_odi = BeautifulSoup(page.content)\n",
    "\n",
    "#to scrape first rank team name\n",
    "\n",
    "team_name = soup_odi.find_all(\"span\", class_=\"u-hide-phablet\")\n",
    "Team = []   #empty list\n",
    "for i in team_name:\n",
    "    Team.append(i.text.replace(\"\\n\",\" \"))\n",
    "Team\n",
    "\n",
    "#to scrape first rank team number of matches\n",
    "\n",
    "odi_matches = soup_odi.find_all(\"td\",class_=\"rankings-block__banner--matches\")\n",
    "Matches = []     #empty list\n",
    "for i in odi_matches:\n",
    "    Matches.append(i.text.replace(\"\\n\",\" \"))\n",
    "Matches\n",
    "        \n",
    "#Scraping the first rank team points\n",
    "\n",
    "odi_points = soup_odi.find_all(\"td\", class_= \"rankings-block__banner--points\")\n",
    "Points = []       #empty list\n",
    "for i in odi_points:\n",
    "    Points.append(i.text.replace(\"\\n\",\" \"))\n",
    "Points\n",
    "        \n",
    "#Scraping the first rank team ratings\n",
    "\n",
    "odi_rating = soup_odi.find_all(\"td\",class_=\"rankings-block__banner--rating u-text-right\")\n",
    "Rating = []\n",
    "for i in odi_rating:\n",
    "    Rating.append(i.text.replace(\"\\n\",\" \"))\n",
    "Rating\n",
    "\n",
    "#scraping the other teams rank, matches, points and ratings\n",
    "new_list = [] #empty list\n",
    "\n",
    "for i in soup_odi.find_all(\"td\",class_='table-body__cell u-center-text'):\n",
    "    new_list.append(i.text)\n",
    "for i in range(0,len(new_list)-1,2):\n",
    "    Matches.append(new_list[i]) \n",
    "    Points.append(new_list[i+1])\n",
    "for i in soup_odi.find_all(\"td\",class_='table-body__cell u-text-right rating'):\n",
    "    Rating.append(i.text)\n",
    "        \n",
    "# Making the data frame \n",
    "df = pd.DataFrame({})\n",
    "df[\"TEAM\"]=Team[:10]\n",
    "df[\"MATCHES\"]=Matches[:10]\n",
    "df[\"POINTS\"]=Points[:10]\n",
    "df[\"RATING\"]=Rating[:10]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) Top 10 ODI Batsmen in men along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shai Hope</td>\n",
       "      <td>WI</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kane Williamson</td>\n",
       "      <td>NZ</td>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Player                        Team Rating\n",
       "0       Babar Azam    PAK                         873\n",
       "1      Virat Kohli                         IND    844\n",
       "2     Rohit Sharma                         IND    813\n",
       "3      Ross Taylor                          NZ    801\n",
       "4      Aaron Finch                         AUS    779\n",
       "5   Jonny Bairstow                         ENG    775\n",
       "6     David Warner                         AUS    762\n",
       "7  Quinton de Kock                          SA    758\n",
       "8        Shai Hope                          WI    758\n",
       "9  Kane Williamson                          NZ    754"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\"\n",
    "page = requests.get(url)\n",
    "print(page)\n",
    "\n",
    "soup_batsmen = BeautifulSoup(page.content)\n",
    "\n",
    "#scraping first rank batsmen name, team name and rating\n",
    "players = []    #empty list\n",
    "team_name = []  #empty list\n",
    "rating = []     #empty list\n",
    "\n",
    "player_name = soup_batsmen.find_all(\"div\", class_= \"rankings-block__banner--name-large\")\n",
    "for i in player_name:\n",
    "    players.append(i.text.replace(\"\\n\",\" \"))\n",
    "\n",
    "\n",
    "team = soup_batsmen.find_all(\"div\",class_=\"rankings-block__banner--nationality\")\n",
    "for i in team:\n",
    "    team_name.append(i.text.replace(\"\\n\",\" \"))\n",
    "    \n",
    "\n",
    "player_rating= soup_batsmen.find_all(\"div\", class_= \"rankings-block__banner--rating\")\n",
    "for i in player_rating:\n",
    "    rating.append(i.text)\n",
    "        \n",
    "#Scraping the other batsmen name,team name and rating\n",
    "for i in soup_batsmen.find_all(\"td\",class_='table-body__cell rankings-table__name name'):# players name\n",
    "    for j in i.find_all('a'):\n",
    "        players.append(j.text)\n",
    "for i in soup_batsmen.find_all(\"span\",class_='table-body__logo-text'): # players team name\n",
    "    team_name.append(i.text)\n",
    "for i in soup_batsmen.find_all(\"td\",class_='table-body__cell rating'): # players rating\n",
    "    rating.append(i.text)\n",
    "\n",
    "        \n",
    "# Make data frame of ICC top 10 Batsmen\n",
    "df=pd.DataFrame({})\n",
    "df[\"Player\"]=players[:10]\n",
    "df[\"Team\"]=team_name[:10]\n",
    "df[\"Rating\"]= rating[:10]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shakib Al Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kagiso Rabada</td>\n",
       "      <td>SA</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player                       Team Rating\n",
       "0       Trent Boult    NZ                         737\n",
       "1    Josh Hazlewood                        AUS    709\n",
       "2  Mujeeb Ur Rahman                        AFG    708\n",
       "3      Chris Woakes                        ENG    700\n",
       "4      Mehedi Hasan                        BAN    692\n",
       "5        Matt Henry                         NZ    691\n",
       "6    Jasprit Bumrah                        IND    679\n",
       "7    Mitchell Starc                        AUS    652\n",
       "8   Shakib Al Hasan                        BAN    650\n",
       "9     Kagiso Rabada                         SA    648"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\"\n",
    "page = requests.get(url)\n",
    "print(page)\n",
    "\n",
    "soup_bowler = BeautifulSoup(page.content)\n",
    "\n",
    "#scraping first rank batsmen name, team name and rating\n",
    "players = []    #empty list\n",
    "team_name = []  #empty list\n",
    "rating = []     #empty list\n",
    "\n",
    "player_name = soup_bowler.find_all(\"div\", class_= \"rankings-block__banner--name-large\")\n",
    "for i in player_name:\n",
    "    players.append(i.text.replace(\"\\n\",\" \"))\n",
    "\n",
    "\n",
    "team = soup_bowler.find_all(\"div\",class_=\"rankings-block__banner--nationality\")\n",
    "for i in team:\n",
    "    team_name.append(i.text.replace(\"\\n\",\" \"))\n",
    "    \n",
    "\n",
    "player_rating= soup_bowler.find_all(\"div\", class_= \"rankings-block__banner--rating\")\n",
    "for i in player_rating:\n",
    "    rating.append(i.text)\n",
    "        \n",
    "#Scraping the other batsmen name,team name and rating\n",
    "for i in soup_bowler.find_all(\"td\",class_='table-body__cell rankings-table__name name'):# players name\n",
    "    for j in i.find_all('a'):\n",
    "        players.append(j.text)\n",
    "for i in soup_bowler.find_all(\"span\",class_='table-body__logo-text'): # players team name\n",
    "    team_name.append(i.text)\n",
    "for i in soup_bowler.find_all(\"td\",class_='table-body__cell rating'): # players rating\n",
    "    rating.append(i.text)\n",
    "\n",
    "        \n",
    "# Make data frame of ICC top 10 Batsmen\n",
    "df=pd.DataFrame({})\n",
    "df[\"Player\"]=players[:10]\n",
    "df[\"Team\"]=team_name[:10]\n",
    "df[\"Rating\"]= rating[:10]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "\n",
    "    i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>18</td>\n",
       "      <td>2,955</td>\n",
       "      <td>164               ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>20</td>\n",
       "      <td>2,370</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>24</td>\n",
       "      <td>2,828</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>23</td>\n",
       "      <td>2,535</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>21</td>\n",
       "      <td>1,947</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>17</td>\n",
       "      <td>1,427</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>20</td>\n",
       "      <td>1,496</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>5</td>\n",
       "      <td>306</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>11</td>\n",
       "      <td>519</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Team Matches Points  \\\n",
       "0     Australia      18  2,955   \n",
       "1       England      20  2,370   \n",
       "2  South Africa      24  2,828   \n",
       "3         India      23  2,535   \n",
       "4   New Zealand      21  1,947   \n",
       "5   West Indies      17  1,427   \n",
       "6      Pakistan      20  1,496   \n",
       "7    Bangladesh       5    306   \n",
       "8     Sri Lanka      11    519   \n",
       "9       Ireland       2     25   \n",
       "\n",
       "                                              Rating  \n",
       "0                              164               ...  \n",
       "1                                                119  \n",
       "2                                                118  \n",
       "3                                                110  \n",
       "4                                                 93  \n",
       "5                                                 84  \n",
       "6                                                 75  \n",
       "7                                                 61  \n",
       "8                                                 47  \n",
       "9                                                 13  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\"\n",
    "page = requests.get(url)\n",
    "print(page)\n",
    "\n",
    "#see content of the page\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "#scraping first rank team names, number of matches, points and ratings\n",
    "womens_matches = [] #empty list\n",
    "womens_points = [] #empty list\n",
    "womens_ratings = [] #empty list\n",
    "womens_new_list = [] #empty list\n",
    "\n",
    "womens_team = soup.find_all(\"span\",class_='u-hide-phablet')\n",
    "womens_team_name = []\n",
    "for i in womens_team:\n",
    "    womens_team_name.append(i.text)\n",
    "\n",
    "for i in soup.find_all(\"td\",class_='rankings-block__banner--matches'):\n",
    "    womens_matches.append(i.text)\n",
    "for i in soup.find_all(\"td\",class_='rankings-block__banner--points'):\n",
    "    womens_points.append(i.text)\n",
    "for i in soup.find_all(\"td\",class_='rankings-block__banner--rating u-text-right'):\n",
    "    womens_ratings.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "#scraping other team names, number of matches, points and ratings\n",
    "for i in soup.find_all(\"td\",class_='table-body__cell u-center-text'):\n",
    "    womens_new_list.append(i.text)\n",
    "for i in range(0,len(womens_new_list)-1,2):\n",
    "    womens_matches.append(womens_new_list[i])\n",
    "    womens_points.append(womens_new_list[i+1])\n",
    "for i in soup.find_all(\"td\",class_='table-body__cell u-text-right rating'):\n",
    "    womens_ratings.append(i.text)\n",
    "\n",
    "# Make data frame of top 10 ICC Women's team ranking\n",
    "df=pd.DataFrame({})\n",
    "df['Team']=womens_team_name[:10]\n",
    "df['Matches']=womens_matches[:10]\n",
    "df['Points']=womens_points[:10]\n",
    "df['Rating']=womens_ratings[:10]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) Top 10 women’s ODI players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mithali Raj</td>\n",
       "      <td>IND</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lizelle Lee</td>\n",
       "      <td>SA</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Player                        Team Rating\n",
       "0        Mithali Raj    IND                         762\n",
       "1        Lizelle Lee                          SA    758\n",
       "2       Alyssa Healy                         AUS    756\n",
       "3     Tammy Beaumont                         ENG    754\n",
       "4    Stafanie Taylor                          WI    736\n",
       "5        Meg Lanning                         AUS    723\n",
       "6  Amy Satterthwaite                          NZ    715\n",
       "7     Natalie Sciver                         ENG    706\n",
       "8    Smriti Mandhana                         IND    701\n",
       "9    Laura Wolvaardt                          SA    683"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\"\n",
    "page = requests.get(url)\n",
    "print(page)\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "#scraping first rank player name, team name and rating\n",
    "players = []    #empty list\n",
    "team_name = []  #empty list\n",
    "rating = []     #empty list\n",
    "\n",
    "player_name = soup.find_all(\"div\", class_= \"rankings-block__banner--name-large\")\n",
    "for i in player_name:\n",
    "    players.append(i.text.replace(\"\\n\",\" \"))\n",
    "\n",
    "\n",
    "team = soup.find_all(\"div\",class_=\"rankings-block__banner--nationality\")\n",
    "for i in team:\n",
    "    team_name.append(i.text.replace(\"\\n\",\" \"))\n",
    "    \n",
    "\n",
    "player_rating= soup.find_all(\"div\", class_= \"rankings-block__banner--rating\")\n",
    "for i in player_rating:\n",
    "    rating.append(i.text)\n",
    "        \n",
    "#Scraping the other batsmen name,team name and rating\n",
    "for i in soup.find_all(\"td\",class_='table-body__cell rankings-table__name name'):\n",
    "    for j in i.find_all('a'):\n",
    "        players.append(j.text)\n",
    "for i in soup.find_all(\"span\",class_='table-body__logo-text'):\n",
    "    team_name.append(i.text)\n",
    "for i in soup.find_all(\"td\",class_='table-body__cell rating'):\n",
    "    rating.append(i.text)\n",
    "\n",
    "        \n",
    "# Make data frame of ICC top 10 Women's ODI Batting Ranking\n",
    "df=pd.DataFrame({})\n",
    "df[\"Player\"]=players[:10]\n",
    "df[\"Team\"]=team_name[:10]\n",
    "df[\"Rating\"]= rating[:10]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dane van Niekerk</td>\n",
       "      <td>SA</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sophie Devine</td>\n",
       "      <td>NZ</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Katherine Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player                       Team Rating\n",
       "0    Marizanne Kapp    SA                         418\n",
       "1      Ellyse Perry                        AUS    418\n",
       "2   Stafanie Taylor                         WI    394\n",
       "3    Natalie Sciver                        ENG    365\n",
       "4     Deepti Sharma                        IND    331\n",
       "5     Jess Jonassen                        AUS    307\n",
       "6  Ashleigh Gardner                        AUS    252\n",
       "7  Dane van Niekerk                         SA    243\n",
       "8     Sophie Devine                         NZ    242\n",
       "9   Katherine Brunt                        ENG    239"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\"\n",
    "page = requests.get(url)\n",
    "print(page)\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "#scraping first rank player name, team name and rating\n",
    "players = []    #empty list\n",
    "team_name = []  #empty list\n",
    "rating = []     #empty list\n",
    "\n",
    "player_name = soup.find_all(\"div\", class_= \"rankings-block__banner--name-large\")\n",
    "for i in player_name:\n",
    "    players.append(i.text.replace(\"\\n\",\" \"))\n",
    "\n",
    "\n",
    "team = soup.find_all(\"div\",class_=\"rankings-block__banner--nationality\")\n",
    "for i in team:\n",
    "    team_name.append(i.text.replace(\"\\n\",\" \"))\n",
    "    \n",
    "\n",
    "player_rating= soup.find_all(\"div\", class_= \"rankings-block__banner--rating\")\n",
    "for i in player_rating:\n",
    "    rating.append(i.text)\n",
    "        \n",
    "#Scraping the other batsmen name,team name and rating\n",
    "for i in soup.find_all(\"td\",class_='table-body__cell rankings-table__name name'):\n",
    "    for j in i.find_all('a'):\n",
    "        players.append(j.text)\n",
    "for i in soup.find_all(\"span\",class_='table-body__logo-text'):\n",
    "    team_name.append(i.text)\n",
    "for i in soup.find_all(\"td\",class_='table-body__cell rating'):\n",
    "    rating.append(i.text)\n",
    "\n",
    "        \n",
    "# Make data frame of ICC top 10 Women's ODI All-Rounder Ranking\n",
    "df=pd.DataFrame({})\n",
    "df[\"Player\"]=players[:10]\n",
    "df[\"Team\"]=team_name[:10]\n",
    "df[\"Rating\"]= rating[:10]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The scraped data should include Product Name, Price, Image URL and Average Rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>img_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Redmi 9A (Nature Green, 2GB RAM, 32GB Storage)...</td>\n",
       "      <td>6,999</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71sxlhYhKW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>realme C11 (2021) (Cool Blue, 2GB RAM, 32GB St...</td>\n",
       "      <td>14,999</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71FYSKYFup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Samsung Galaxy M31 (Ocean Blue, 6GB RAM, 128GB...</td>\n",
       "      <td>14,999</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71-Su4Wr0H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Samsung Galaxy M31 (Space Black, 6GB RAM, 128G...</td>\n",
       "      <td>13,499</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71OxJeyywS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Redmi 9 Power (Mighty Black, 6GB RAM, 128GB St...</td>\n",
       "      <td>14,999</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61LHaUOheh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Redmi Note 10S (Shadow Black, 6GB RAM, 64GB St...</td>\n",
       "      <td>13,499</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/81R9c74pmD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Redmi 9 Power (Blazing Blue, 6GB RAM, 128GB St...</td>\n",
       "      <td>16,999</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71hEzQGO5q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Samsung Galaxy M31 (Ocean Blue, 8GB RAM, 128GB...</td>\n",
       "      <td>12,490</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71-Su4Wr0H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Oppo A31 (Fantasy White, 6GB RAM, 128GB Storag...</td>\n",
       "      <td>11,999</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61CnyJ-IbM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Redmi Note 9 (Pebble Grey, 4GB RAM 64GB Storag...</td>\n",
       "      <td>6,999</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71X5I1cVfb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Redmi 9A (Midnight Black, 2GB RAM, 32GB Storag...</td>\n",
       "      <td>5,798</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71sxlhYhKW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Panasonic Eluga i7 (2GB RAM, 16GB Storage, Fin...</td>\n",
       "      <td>7,999</td>\n",
       "      <td>3.1 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/41QsvcpKaZ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Redmi 9A (Sea Blue 3GB RAM 32GB Storage)| 2GHz...</td>\n",
       "      <td>10,499</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71sxlhYhKW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Samsung Galaxy M02s (Black,4GB RAM, 64GB Stora...</td>\n",
       "      <td>10,990</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71IkA3T7hI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>OPPO A31 (Mystery Black, 4GB RAM, 64GB Storage...</td>\n",
       "      <td>13,999</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71KCwNV6Mu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Product Name   Price  \\\n",
       "0   Redmi 9A (Nature Green, 2GB RAM, 32GB Storage)...   6,999   \n",
       "1   realme C11 (2021) (Cool Blue, 2GB RAM, 32GB St...  14,999   \n",
       "2   Samsung Galaxy M31 (Ocean Blue, 6GB RAM, 128GB...  14,999   \n",
       "3   Samsung Galaxy M31 (Space Black, 6GB RAM, 128G...  13,499   \n",
       "4   Redmi 9 Power (Mighty Black, 6GB RAM, 128GB St...  14,999   \n",
       "5   Redmi Note 10S (Shadow Black, 6GB RAM, 64GB St...  13,499   \n",
       "6   Redmi 9 Power (Blazing Blue, 6GB RAM, 128GB St...  16,999   \n",
       "7   Samsung Galaxy M31 (Ocean Blue, 8GB RAM, 128GB...  12,490   \n",
       "8   Oppo A31 (Fantasy White, 6GB RAM, 128GB Storag...  11,999   \n",
       "9   Redmi Note 9 (Pebble Grey, 4GB RAM 64GB Storag...   6,999   \n",
       "10  Redmi 9A (Midnight Black, 2GB RAM, 32GB Storag...   5,798   \n",
       "11  Panasonic Eluga i7 (2GB RAM, 16GB Storage, Fin...   7,999   \n",
       "12  Redmi 9A (Sea Blue 3GB RAM 32GB Storage)| 2GHz...  10,499   \n",
       "13  Samsung Galaxy M02s (Black,4GB RAM, 64GB Stora...  10,990   \n",
       "14  OPPO A31 (Mystery Black, 4GB RAM, 64GB Storage...  13,999   \n",
       "\n",
       "                Rating                                            img_url  \n",
       "0   4.2 out of 5 stars  https://m.media-amazon.com/images/I/71sxlhYhKW...  \n",
       "1   4.1 out of 5 stars  https://m.media-amazon.com/images/I/71FYSKYFup...  \n",
       "2   4.3 out of 5 stars  https://m.media-amazon.com/images/I/71-Su4Wr0H...  \n",
       "3   4.3 out of 5 stars  https://m.media-amazon.com/images/I/71OxJeyywS...  \n",
       "4   4.2 out of 5 stars  https://m.media-amazon.com/images/I/61LHaUOheh...  \n",
       "5   4.1 out of 5 stars  https://m.media-amazon.com/images/I/81R9c74pmD...  \n",
       "6   4.2 out of 5 stars  https://m.media-amazon.com/images/I/71hEzQGO5q...  \n",
       "7   4.3 out of 5 stars  https://m.media-amazon.com/images/I/71-Su4Wr0H...  \n",
       "8   4.2 out of 5 stars  https://m.media-amazon.com/images/I/61CnyJ-IbM...  \n",
       "9   4.3 out of 5 stars  https://m.media-amazon.com/images/I/71X5I1cVfb...  \n",
       "10  4.2 out of 5 stars  https://m.media-amazon.com/images/I/71sxlhYhKW...  \n",
       "11  3.1 out of 5 stars  https://m.media-amazon.com/images/I/41QsvcpKaZ...  \n",
       "12  4.2 out of 5 stars  https://m.media-amazon.com/images/I/71sxlhYhKW...  \n",
       "13  4.1 out of 5 stars  https://m.media-amazon.com/images/I/71IkA3T7hI...  \n",
       "14  4.2 out of 5 stars  https://m.media-amazon.com/images/I/71KCwNV6Mu...  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.amazon.in/s?k=phones+under+20000+rupees&ref=nb_sb_noss_1\"\n",
    "page = requests.get(url)\n",
    "print(page)\n",
    "\n",
    "#to see content in page\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "#empty lists\n",
    "product_name = []  \n",
    "price = []    \n",
    "rating = []   \n",
    "img_url = []   \n",
    "\n",
    "\n",
    "# to Scrape product name\n",
    "for i in soup.find_all(\"span\",class_=\"a-size-medium a-color-base a-text-normal\"):\n",
    "    product_name.append(i.text)\n",
    "\n",
    "#  toScrape product price\n",
    "for i in soup.find_all(\"span\",class_=\"a-price-whole\"):\n",
    "    price.append(i.text)\n",
    "    \n",
    "# to scrape product rating\n",
    "for i in soup.find_all(\"span\",class_=\"a-icon-alt\"):\n",
    "    rating.append(i.text)\n",
    "\n",
    "# to Scrape images url\n",
    "for i in soup.find_all(\"img\",class_=\"s-image\"):\n",
    "    img_url.append(i.get(\"src\"))\n",
    "    \n",
    "# Make data frame mobile phones under Rs. 20,000 listed on Amazon.in\n",
    "df=pd.DataFrame({})\n",
    "df['Product Name']=product_name[:15]\n",
    "df['Price']=price[:15]\n",
    "df['Rating']=rating[:15]\n",
    "df['img_url'] = img_url[:15]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Write a python program to extract information about the local weather from the National Weather Service website of USA, https://www.weather.gov/ for the city, San Francisco. You need to extract data about 7 day extended forecast display for the city. The data should include period, short description, temperature and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Period</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Short_description</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Today</td>\n",
       "      <td>High: 65 °F</td>\n",
       "      <td>DecreasingClouds</td>\n",
       "      <td>Mostly cloudy, then gradually becoming sunny, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tonight</td>\n",
       "      <td>Low: 54 °F</td>\n",
       "      <td>IncreasingClouds</td>\n",
       "      <td>Increasing clouds, with a low around 54. West ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>High: 65 °F</td>\n",
       "      <td>GradualClearing</td>\n",
       "      <td>Cloudy through mid morning, then gradual clear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wednesday Night</td>\n",
       "      <td>Low: 55 °F</td>\n",
       "      <td>Mostly Clearand Breezythen PartlyCloudy</td>\n",
       "      <td>Partly cloudy, with a low around 55. Breezy, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>High: 71 °F</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Sunny, with a high near 71. Light south southw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Thursday Night</td>\n",
       "      <td>Low: 57 °F</td>\n",
       "      <td>Mostly Clear</td>\n",
       "      <td>Mostly clear, with a low around 57.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Friday</td>\n",
       "      <td>High: 75 °F</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Sunny, with a high near 75.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Friday Night</td>\n",
       "      <td>Low: 57 °F</td>\n",
       "      <td>Mostly Clear</td>\n",
       "      <td>Mostly clear, with a low around 57.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>High: 75 °F</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Sunny, with a high near 75.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Period  Temperature                        Short_description  \\\n",
       "0            Today  High: 65 °F                         DecreasingClouds   \n",
       "1          Tonight   Low: 54 °F                         IncreasingClouds   \n",
       "2        Wednesday  High: 65 °F                          GradualClearing   \n",
       "3  Wednesday Night   Low: 55 °F  Mostly Clearand Breezythen PartlyCloudy   \n",
       "4         Thursday  High: 71 °F                                    Sunny   \n",
       "5   Thursday Night   Low: 57 °F                             Mostly Clear   \n",
       "6           Friday  High: 75 °F                                    Sunny   \n",
       "7     Friday Night   Low: 57 °F                             Mostly Clear   \n",
       "8         Saturday  High: 75 °F                                    Sunny   \n",
       "\n",
       "                                         Description  \n",
       "0  Mostly cloudy, then gradually becoming sunny, ...  \n",
       "1  Increasing clouds, with a low around 54. West ...  \n",
       "2  Cloudy through mid morning, then gradual clear...  \n",
       "3  Partly cloudy, with a low around 55. Breezy, w...  \n",
       "4  Sunny, with a high near 71. Light south southw...  \n",
       "5                Mostly clear, with a low around 57.  \n",
       "6                        Sunny, with a high near 75.  \n",
       "7                Mostly clear, with a low around 57.  \n",
       "8                        Sunny, with a high near 75.  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41963999999996#.YSTNP8_hXIU\"\n",
    "page = requests.get(url)\n",
    "print(page)\n",
    "\n",
    "# to see content of the page\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "# Scraping details of period, temperature, short description, and description about 7 day extended forecast.\n",
    "period = []        #empty list\n",
    "short_desc = []    #empty list\n",
    "temperature = []   #empty list\n",
    "description = []   #empty list\n",
    "\n",
    "for i in soup.find_all(\"div\", class_=\"col-sm-2 forecast-label\"):\n",
    "    period.append(i.text)\n",
    "\n",
    "for i in soup.find_all('p',attrs={'short-desc'}):\n",
    "        if i.next_sibling is not None:\n",
    "            temperature.append(i.next_sibling.text)\n",
    "        else:\n",
    "            temperature.append(' ')\n",
    "\n",
    "for i in soup.find_all('p',class_=\"short-desc\"):        \n",
    "        short_desc.append(i.text.split(',')[0])\n",
    "    \n",
    "for i in soup.find_all(\"div\", class_=\"col-sm-10 forecast-text\"):\n",
    "        description.append(i.text)\n",
    "\n",
    "# to see the data frame about 7 day extended forecast\n",
    "df = pd.DataFrame({})\n",
    "df['Period']=period[:9]\n",
    "df['Temperature']=temperature[:9]\n",
    "df['Short_description']=short_desc[:9]\n",
    "df['Description']=description[:9]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Write a python program to scrape fresher job listings from ‘https://internshala.com/’. It should include job title, company name, CTC, and apply date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>CTC</th>\n",
       "      <th>Apply Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OMNI SPORT LEADER</td>\n",
       "      <td>Decathlon Sport India Private Limited</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>18 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Executive/Senior Executive - Partnerships</td>\n",
       "      <td>Freecharge Payments Technology Private Limited</td>\n",
       "      <td>3 - 4.2 LPA</td>\n",
       "      <td>11 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Executive - Sales</td>\n",
       "      <td>Freecharge Payments Technology Private Limited</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>11 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Junior Operations Executive</td>\n",
       "      <td>Freecharge Payments Technology Private Limited</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>4 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mobile App Developer</td>\n",
       "      <td>Cogent Web Services</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>23 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Software Developer</td>\n",
       "      <td>Swabhav Techlabs</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>23 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Coding Teacher (Remote)</td>\n",
       "      <td>Codingal Education Private Limited</td>\n",
       "      <td>3 - 6 LPA</td>\n",
       "      <td>23 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Validation Expert</td>\n",
       "      <td>Apna</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>23 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>ImbueDesk</td>\n",
       "      <td>5 - 9 LPA</td>\n",
       "      <td>23 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Business Development Associate</td>\n",
       "      <td>Tutedude</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>23 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Content &amp; E-commerce Management Executive</td>\n",
       "      <td>Anmol Baby</td>\n",
       "      <td>3 - 3.1 LPA</td>\n",
       "      <td>23 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Business Development Specialist</td>\n",
       "      <td>The SmartWare</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>23 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Assistant Manager - Outreach &amp; Events</td>\n",
       "      <td>Formskart</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>23 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Investor Pitch Deck - Content Writer</td>\n",
       "      <td>PitchyDeck</td>\n",
       "      <td>3 - 4.5 LPA</td>\n",
       "      <td>23 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Full Stack Engineer (MERN)</td>\n",
       "      <td>Softway Solutions Private Limited</td>\n",
       "      <td>5.5 - 8 LPA</td>\n",
       "      <td>23 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Volopay</td>\n",
       "      <td>3.6 - 5 LPA</td>\n",
       "      <td>23 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Junior Graphic Designer</td>\n",
       "      <td>Habitate Technologies Private Limited</td>\n",
       "      <td>3.2 - 3.6 LPA</td>\n",
       "      <td>23 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sales Development Representative</td>\n",
       "      <td>Ziguar</td>\n",
       "      <td>4 - 6 LPA</td>\n",
       "      <td>23 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Junior Sales Executive</td>\n",
       "      <td>Picocrew</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>23 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Online Coding Educator</td>\n",
       "      <td>BrightChamps Tech Private Limited</td>\n",
       "      <td>3 - 7.5 LPA</td>\n",
       "      <td>23 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Executive - Statistical Modeling</td>\n",
       "      <td>D'Well Research</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>23 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Customer Experience And Sales Advisor</td>\n",
       "      <td>Tilfi Banaras</td>\n",
       "      <td>3 - 4.8 LPA</td>\n",
       "      <td>23 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Firmware Engineer</td>\n",
       "      <td>NBase2 Systems Private Limited</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>22 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Junior Software Developer</td>\n",
       "      <td>Finnovus Technologies Private Limited (CreditS...</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>22 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Full Stack Engineer</td>\n",
       "      <td>Getart</td>\n",
       "      <td>4 - 6 LPA</td>\n",
       "      <td>22 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Backend Developer (Java/Spring Boot/Hibernate)</td>\n",
       "      <td>Krenai</td>\n",
       "      <td>3.4 - 4.5 LPA</td>\n",
       "      <td>22 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Associate Content Writer</td>\n",
       "      <td>MiM-Essay</td>\n",
       "      <td>4 - 4.5 LPA</td>\n",
       "      <td>22 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Social Media Manager</td>\n",
       "      <td>Finvision Financial Services</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>22 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Retail Store Manager</td>\n",
       "      <td>Etchcraft</td>\n",
       "      <td>3 - 3.6 LPA</td>\n",
       "      <td>22 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Autocad Operator</td>\n",
       "      <td>Dolphin Engineers</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>22 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Business Development/Growth Executive</td>\n",
       "      <td>Flurn Technologies</td>\n",
       "      <td>3 - 6 LPA</td>\n",
       "      <td>22 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Administration Manager</td>\n",
       "      <td>Easy Entertainment</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>22 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Junior Full Stack Developer</td>\n",
       "      <td>BLOOMING RECALL LLP</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>22 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Software Developer Trainee</td>\n",
       "      <td>Pinnacle Software And Services Private Limited</td>\n",
       "      <td>3.25 - 3.75 LPA</td>\n",
       "      <td>22 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>UI/UX Designer</td>\n",
       "      <td>Masterstroke Media Private Limited</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>22 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Business Development Associate</td>\n",
       "      <td>Karmic Seed</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>22 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Embedded Systems Associate</td>\n",
       "      <td>Embedded Technosolutions</td>\n",
       "      <td>3 - 3.2 LPA</td>\n",
       "      <td>22 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Digital Marketing Executive</td>\n",
       "      <td>Triny.io</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>22 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Node.js &amp; React.js Developer</td>\n",
       "      <td>Saino First Network Private Limited</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>22 Sep' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Front-End Engineer</td>\n",
       "      <td>AffinityAnswers</td>\n",
       "      <td>5 - 6.5 LPA</td>\n",
       "      <td>22 Sep' 21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Job Title  \\\n",
       "0                                OMNI SPORT LEADER    \n",
       "1        Executive/Senior Executive - Partnerships    \n",
       "2                                Executive - Sales    \n",
       "3                      Junior Operations Executive    \n",
       "4                             Mobile App Developer    \n",
       "5                               Software Developer    \n",
       "6                          Coding Teacher (Remote)    \n",
       "7                                Validation Expert    \n",
       "8                             Full Stack Developer    \n",
       "9                   Business Development Associate    \n",
       "10       Content & E-commerce Management Executive    \n",
       "11                 Business Development Specialist    \n",
       "12           Assistant Manager - Outreach & Events    \n",
       "13            Investor Pitch Deck - Content Writer    \n",
       "14                      Full Stack Engineer (MERN)    \n",
       "15                  Business Development Executive    \n",
       "16                         Junior Graphic Designer    \n",
       "17                Sales Development Representative    \n",
       "18                          Junior Sales Executive    \n",
       "19                          Online Coding Educator    \n",
       "20                Executive - Statistical Modeling    \n",
       "21           Customer Experience And Sales Advisor    \n",
       "22                               Firmware Engineer    \n",
       "23                       Junior Software Developer    \n",
       "24                             Full Stack Engineer    \n",
       "25  Backend Developer (Java/Spring Boot/Hibernate)    \n",
       "26                        Associate Content Writer    \n",
       "27                            Social Media Manager    \n",
       "28                            Retail Store Manager    \n",
       "29                                Autocad Operator    \n",
       "30           Business Development/Growth Executive    \n",
       "31                          Administration Manager    \n",
       "32                     Junior Full Stack Developer    \n",
       "33                      Software Developer Trainee    \n",
       "34                                  UI/UX Designer    \n",
       "35                  Business Development Associate    \n",
       "36                      Embedded Systems Associate    \n",
       "37                     Digital Marketing Executive    \n",
       "38                    Node.js & React.js Developer    \n",
       "39                              Front-End Engineer    \n",
       "\n",
       "                                         Company Name              CTC  \\\n",
       "0               Decathlon Sport India Private Limited        3 - 4 LPA   \n",
       "1      Freecharge Payments Technology Private Limited      3 - 4.2 LPA   \n",
       "2      Freecharge Payments Technology Private Limited      3 - 3.5 LPA   \n",
       "3      Freecharge Payments Technology Private Limited        3 - 4 LPA   \n",
       "4                                 Cogent Web Services            3 LPA   \n",
       "5                                    Swabhav Techlabs      3 - 3.5 LPA   \n",
       "6                  Codingal Education Private Limited        3 - 6 LPA   \n",
       "7                                                Apna            3 LPA   \n",
       "8                                           ImbueDesk        5 - 9 LPA   \n",
       "9                                            Tutedude        3 - 4 LPA   \n",
       "10                                         Anmol Baby      3 - 3.1 LPA   \n",
       "11                                      The SmartWare            3 LPA   \n",
       "12                                          Formskart            3 LPA   \n",
       "13                                         PitchyDeck      3 - 4.5 LPA   \n",
       "14                  Softway Solutions Private Limited      5.5 - 8 LPA   \n",
       "15                                            Volopay      3.6 - 5 LPA   \n",
       "16              Habitate Technologies Private Limited    3.2 - 3.6 LPA   \n",
       "17                                             Ziguar        4 - 6 LPA   \n",
       "18                                           Picocrew            3 LPA   \n",
       "19                  BrightChamps Tech Private Limited      3 - 7.5 LPA   \n",
       "20                                    D'Well Research      3 - 3.5 LPA   \n",
       "21                                      Tilfi Banaras      3 - 4.8 LPA   \n",
       "22                     NBase2 Systems Private Limited            3 LPA   \n",
       "23  Finnovus Technologies Private Limited (CreditS...      3 - 3.5 LPA   \n",
       "24                                             Getart        4 - 6 LPA   \n",
       "25                                             Krenai    3.4 - 4.5 LPA   \n",
       "26                                          MiM-Essay      4 - 4.5 LPA   \n",
       "27                       Finvision Financial Services      3 - 3.5 LPA   \n",
       "28                                          Etchcraft      3 - 3.6 LPA   \n",
       "29                                  Dolphin Engineers            3 LPA   \n",
       "30                                 Flurn Technologies        3 - 6 LPA   \n",
       "31                                 Easy Entertainment            3 LPA   \n",
       "32                                BLOOMING RECALL LLP        3 - 5 LPA   \n",
       "33     Pinnacle Software And Services Private Limited  3.25 - 3.75 LPA   \n",
       "34                 Masterstroke Media Private Limited      3 - 3.5 LPA   \n",
       "35                                        Karmic Seed        3 - 5 LPA   \n",
       "36                           Embedded Technosolutions      3 - 3.2 LPA   \n",
       "37                                           Triny.io        3 - 5 LPA   \n",
       "38                Saino First Network Private Limited        3 - 5 LPA   \n",
       "39                                    AffinityAnswers      5 - 6.5 LPA   \n",
       "\n",
       "    Apply Date  \n",
       "0   18 Sep' 21  \n",
       "1   11 Sep' 21  \n",
       "2   11 Sep' 21  \n",
       "3    4 Sep' 21  \n",
       "4   23 Sep' 21  \n",
       "5   23 Sep' 21  \n",
       "6   23 Sep' 21  \n",
       "7   23 Sep' 21  \n",
       "8   23 Sep' 21  \n",
       "9   23 Sep' 21  \n",
       "10  23 Sep' 21  \n",
       "11  23 Sep' 21  \n",
       "12  23 Sep' 21  \n",
       "13  23 Sep' 21  \n",
       "14  23 Sep' 21  \n",
       "15  23 Sep' 21  \n",
       "16  23 Sep' 21  \n",
       "17  23 Sep' 21  \n",
       "18  23 Sep' 21  \n",
       "19  23 Sep' 21  \n",
       "20  23 Sep' 21  \n",
       "21  23 Sep' 21  \n",
       "22  22 Sep' 21  \n",
       "23  22 Sep' 21  \n",
       "24  22 Sep' 21  \n",
       "25  22 Sep' 21  \n",
       "26  22 Sep' 21  \n",
       "27  22 Sep' 21  \n",
       "28  22 Sep' 21  \n",
       "29  22 Sep' 21  \n",
       "30  22 Sep' 21  \n",
       "31  22 Sep' 21  \n",
       "32  22 Sep' 21  \n",
       "33  22 Sep' 21  \n",
       "34  22 Sep' 21  \n",
       "35  22 Sep' 21  \n",
       "36  22 Sep' 21  \n",
       "37  22 Sep' 21  \n",
       "38  22 Sep' 21  \n",
       "39  22 Sep' 21  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://internshala.com/fresher-jobs\"\n",
    "page = requests.get(url)\n",
    "print(page)\n",
    "\n",
    "# to see the content of page\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "#empty lists\n",
    "job_title = []  \n",
    "company_name = [] \n",
    "CTC = []\n",
    "apply_date = []\n",
    "\n",
    "# to scrape job title\n",
    "title = soup.find_all('div',class_=\"heading_4_5 profile\") \n",
    "for i in title:\n",
    "    job_title.append(i.text.replace('\\n', ''))\n",
    "    \n",
    "#to scrape company names    \n",
    "company = soup.find_all('div',class_=\"heading_6 company_name\")\n",
    "for i in company:\n",
    "    company_name.append(i.text.strip())\n",
    "\n",
    "\n",
    "#to scrape CTC and apply date\n",
    "info = []\n",
    "job_info = soup.find_all(\"div\",class_=\"item_body\")\n",
    "for i in job_info:\n",
    "    info.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "# for apply date    \n",
    "for i in range(2,len(info),3):\n",
    "    apply_date.append(info[i].strip())\n",
    "# for CTC    \n",
    "for i in range(1,len(info),3):\n",
    "    CTC.append(info[i].strip())\n",
    "    \n",
    "    \n",
    "\n",
    "# Make data frame\n",
    "JOB=pd.DataFrame({})\n",
    "JOB['Job Title']=job_title\n",
    "JOB['Company Name']=company_name\n",
    "JOB['CTC']=CTC\n",
    "JOB['Apply Date']=apply_date\n",
    "JOB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Write a python program to scrape house details from https://www.nobroker.in/ for any location. It should include house title, location, area, emi and price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HOUSE</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>AREA</th>\n",
       "      <th>EMI</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4+ BHK Flat  For Sale  In Rohini</td>\n",
       "      <td>Standalone Building, Sector 16, near Shantinat...</td>\n",
       "      <td>[839 sqft]</td>\n",
       "      <td>₹31,522/Month</td>\n",
       "      <td>₹55 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4+ BHK Flat  For Sale  In 9015385307 In Rohini</td>\n",
       "      <td>Sector 16A, Near AJ's Law OfficeExplore Nearby</td>\n",
       "      <td>[2,800 sqft]</td>\n",
       "      <td>₹1.72 Lacs/Month</td>\n",
       "      <td>₹3 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4+ BHK In Independent House  For Sale  In  Sec...</td>\n",
       "      <td>Independent House, Giani Gurumukhi Musaphir Ma...</td>\n",
       "      <td>[2,200 sqft]</td>\n",
       "      <td>₹40,120/Month</td>\n",
       "      <td>₹70 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4+ BHK Flat  For Sale  In G.s. Appartments In ...</td>\n",
       "      <td>Plot No. 103, I.P.Extension, Rohini, Delhi, 11...</td>\n",
       "      <td>[2,000 sqft]</td>\n",
       "      <td>₹1.15 Lacs/Month</td>\n",
       "      <td>₹2 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4+ BHK Flat  For Sale  In  Rohini</td>\n",
       "      <td>standalone building, Sector 11, Near DDA Marke...</td>\n",
       "      <td>[2,240 sqft]</td>\n",
       "      <td>₹94,568/Month</td>\n",
       "      <td>₹1.65 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4+ BHK Flat  For Sale  In Pink View Apartment ...</td>\n",
       "      <td>Sector 18, Near Delhi Police Crime BranchExplo...</td>\n",
       "      <td>[2,200 sqft]</td>\n",
       "      <td>₹91,703/Month</td>\n",
       "      <td>₹1.6 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4+ BHK Flat  For Sale  In Pink View Apartment ...</td>\n",
       "      <td>Sector 18, Near Delhi Police Crime BranchExplo...</td>\n",
       "      <td>[3,200 sqft]</td>\n",
       "      <td>₹1.72 Lacs/Month</td>\n",
       "      <td>₹3 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4+ BHK Flat  For Sale  In Pink View Apartment ...</td>\n",
       "      <td>Sector 18, Near Delhi Police Crime BranchExplo...</td>\n",
       "      <td>[1,550 sqft]</td>\n",
       "      <td>₹74,508/Month</td>\n",
       "      <td>₹1.3 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4+ BHK Flat  For Sale  In Najafgarh,</td>\n",
       "      <td>standalone Building, Ranaji Enclave, Masudabad...</td>\n",
       "      <td>[2,025 sqft]</td>\n",
       "      <td>₹20,060/Month</td>\n",
       "      <td>₹35 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4+ BHK In Independent House  For Sale  In Utta...</td>\n",
       "      <td>Independent House, Hastsal Vihar near  Vasundh...</td>\n",
       "      <td>[2,600 sqft]</td>\n",
       "      <td>₹40,120/Month</td>\n",
       "      <td>₹70 Lacs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               HOUSE  \\\n",
       "0                  4+ BHK Flat  For Sale  In Rohini    \n",
       "1    4+ BHK Flat  For Sale  In 9015385307 In Rohini    \n",
       "2  4+ BHK In Independent House  For Sale  In  Sec...   \n",
       "3  4+ BHK Flat  For Sale  In G.s. Appartments In ...   \n",
       "4                 4+ BHK Flat  For Sale  In  Rohini    \n",
       "5  4+ BHK Flat  For Sale  In Pink View Apartment ...   \n",
       "6  4+ BHK Flat  For Sale  In Pink View Apartment ...   \n",
       "7  4+ BHK Flat  For Sale  In Pink View Apartment ...   \n",
       "8              4+ BHK Flat  For Sale  In Najafgarh,    \n",
       "9  4+ BHK In Independent House  For Sale  In Utta...   \n",
       "\n",
       "                                            LOCATION          AREA  \\\n",
       "0  Standalone Building, Sector 16, near Shantinat...    [839 sqft]   \n",
       "1     Sector 16A, Near AJ's Law OfficeExplore Nearby  [2,800 sqft]   \n",
       "2  Independent House, Giani Gurumukhi Musaphir Ma...  [2,200 sqft]   \n",
       "3  Plot No. 103, I.P.Extension, Rohini, Delhi, 11...  [2,000 sqft]   \n",
       "4  standalone building, Sector 11, Near DDA Marke...  [2,240 sqft]   \n",
       "5  Sector 18, Near Delhi Police Crime BranchExplo...  [2,200 sqft]   \n",
       "6  Sector 18, Near Delhi Police Crime BranchExplo...  [3,200 sqft]   \n",
       "7  Sector 18, Near Delhi Police Crime BranchExplo...  [1,550 sqft]   \n",
       "8  standalone Building, Ranaji Enclave, Masudabad...  [2,025 sqft]   \n",
       "9  Independent House, Hastsal Vihar near  Vasundh...  [2,600 sqft]   \n",
       "\n",
       "                EMI         PRICE  \n",
       "0     ₹31,522/Month      ₹55 Lacs  \n",
       "1  ₹1.72 Lacs/Month     ₹3 Crores  \n",
       "2     ₹40,120/Month      ₹70 Lacs  \n",
       "3  ₹1.15 Lacs/Month     ₹2 Crores  \n",
       "4     ₹94,568/Month  ₹1.65 Crores  \n",
       "5     ₹91,703/Month   ₹1.6 Crores  \n",
       "6  ₹1.72 Lacs/Month     ₹3 Crores  \n",
       "7     ₹74,508/Month   ₹1.3 Crores  \n",
       "8     ₹20,060/Month      ₹35 Lacs  \n",
       "9     ₹40,120/Month      ₹70 Lacs  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.nobroker.in/property/sale/delhi/multiple?searchParam=W3sibGF0IjoyOC41NDc4ODk3LCJsb24iOjc3LjIwMzEyNDcsInBsYWNlSWQiOiJDaElKSTgtaGZSTGlERGtSVFJOcHhpRzhudGciLCJwbGFjZU5hbWUiOiJIYXV6IEtoYXMifSx7ImxhdCI6MjguNjA5MDEyNiwibG9uIjo3Ni45ODU0NTI2LCJwbGFjZUlkIjoiQ2hJSklUclZ0TndQRFRrUndKX3o5NExVQUlnIiwicGxhY2VOYW1lIjoiTmFqYWZnYXJoIn0seyJsYXQiOjI4LjczMTgyOSwibG9uIjo3Ny4xMjUyMjUsInBsYWNlSWQiOiJDaElKTzhNVDBUOEJEVGtSQUktV080YktLaW8iLCJwbGFjZU5hbWUiOiJSb2hpbmkgU2VjLiAxNiJ9XQ==&radius=2.0&type=BHK4PLUS&propertyAge=0\"\n",
    "page = requests.get(url)\n",
    "print(page)\n",
    "\n",
    "# to see content of the page\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "#empty lists\n",
    "house = []  \n",
    "location = [] \n",
    "area = []\n",
    "EMI = [] \n",
    "price = []\n",
    "\n",
    "\n",
    "# to scrape house title details\n",
    "houses = soup.find_all(\"h2\", class_=\"heading-6 font-semi-bold nb__1AShY\")\n",
    "for i in houses:\n",
    "    house.append(i.text)\n",
    "    \n",
    "#to scrape house location details    \n",
    "loc = soup.find_all('div',class_=\"nb__35Ol7\")\n",
    "for i in loc:\n",
    "    location.append(i.text)\n",
    "    \n",
    "#to scrape house area details    \n",
    "Area = soup.find_all('div',class_=\"nb__3oNyC\")\n",
    "for i in area:\n",
    "    area.append(i.text)\n",
    "    \n",
    "#to scrape house EMI and Price\n",
    "info = []\n",
    "detail = soup.find_all('div',class_=\"font-semi-bold heading-6\")\n",
    "for i in detail:\n",
    "    info.append(i.text)\n",
    "\n",
    "for i in range(1,len(info),3):   #EMI details\n",
    "    EMI.append(info[i])\n",
    "\n",
    "for i in range(2,len(info),3):  #price details\n",
    "    price.append(info[i])\n",
    "\n",
    "# Make data frame\n",
    "df=pd.DataFrame({})\n",
    "df['HOUSE']=house\n",
    "df['LOCATION']=location\n",
    "df['AREA']=Area\n",
    "df['EMI']=EMI\n",
    "df['PRICE']=price\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
